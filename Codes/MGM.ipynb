{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xz0eks1t3Ss",
        "outputId": "afb93ee6-4213-4cf0-fbf4-7c3818b33995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'MGM'...\n",
            "remote: Enumerating objects: 579, done.\u001b[K\n",
            "remote: Counting objects: 100% (202/202), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 579 (delta 127), reused 172 (delta 112), pack-reused 377 (from 1)\u001b[K\n",
            "Receiving objects: 100% (579/579), 58.50 MiB | 15.85 MiB/s, done.\n",
            "Resolving deltas: 100% (255/255), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dvlab-research/MGM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMoewM2XsDDy",
        "outputId": "6c97f6b1-2ee5-4c3f-b141-f59cbf9a91b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/MGM\n"
          ]
        }
      ],
      "source": [
        "%cd MGM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcR6buFLkZxo",
        "outputId": "ec491f65-8bfa-400f-c740-bb9b4a672885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-25.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.0\n",
            "Obtaining file:///content/MGM\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch==2.0.1 (from mgm==1.0.0)\n",
            "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.15.2 (from mgm==1.0.0)\n",
            "  Downloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting transformers==4.36.2 (from mgm==1.0.0)\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
            "Collecting tokenizers==0.15.0 (from mgm==1.0.0)\n",
            "  Downloading tokenizers-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting sentencepiece==0.1.99 (from mgm==1.0.0)\n",
            "  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting shortuuid (from mgm==1.0.0)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting accelerate==0.21.0 (from mgm==1.0.0)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting peft==0.4.0 (from mgm==1.0.0)\n",
            "  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting bitsandbytes==0.41.0 (from mgm==1.0.0)\n",
            "  Downloading bitsandbytes-0.41.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pydantic<2,>=1 (from mgm==1.0.0)\n",
            "  Downloading pydantic-1.10.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (153 kB)\n",
            "Collecting markdown2[all] (from mgm==1.0.0)\n",
            "  Downloading markdown2-2.5.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mgm==1.0.0) (1.26.4)\n",
            "Collecting scikit-learn==1.2.2 (from mgm==1.0.0)\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting gradio==3.35.2 (from mgm==1.0.0)\n",
            "  Downloading gradio-3.35.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting gradio_client==0.2.9 (from mgm==1.0.0)\n",
            "  Downloading gradio_client-0.2.9-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from mgm==1.0.0) (2.32.3)\n",
            "Collecting httpx==0.24.0 (from mgm==1.0.0)\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting uvicorn (from mgm==1.0.0)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting fastapi (from mgm==1.0.0)\n",
            "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting einops==0.6.1 (from mgm==1.0.0)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting einops-exts==0.0.4 (from mgm==1.0.0)\n",
            "  Downloading einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\n",
            "Collecting timm==0.9.16 (from mgm==1.0.0)\n",
            "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.21.0->mgm==1.0.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.21.0->mgm==1.0.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.21.0->mgm==1.0.0) (6.0.2)\n",
            "Collecting aiofiles (from gradio==3.35.2->mgm==1.0.0)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from gradio==3.35.2->mgm==1.0.0) (3.11.11)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.35.2->mgm==1.0.0) (5.5.0)\n",
            "Collecting ffmpy (from gradio==3.35.2->mgm==1.0.0)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.35.2->mgm==1.0.0) (0.27.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from gradio==3.35.2->mgm==1.0.0) (3.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->mgm==1.0.0) (3.0.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.11/dist-packages (from gradio==3.35.2->mgm==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from gradio==3.35.2->mgm==1.0.0) (3.10.0)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.35.2->mgm==1.0.0)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from gradio==3.35.2->mgm==1.0.0) (3.10.15)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from gradio==3.35.2->mgm==1.0.0) (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from gradio==3.35.2->mgm==1.0.0) (11.1.0)\n",
            "Collecting pydub (from gradio==3.35.2->mgm==1.0.0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.35.2->mgm==1.0.0) (2.18.0)\n",
            "Collecting python-multipart (from gradio==3.35.2->mgm==1.0.0)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting semantic-version (from gradio==3.35.2->mgm==1.0.0)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.35.2->mgm==1.0.0) (14.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio_client==0.2.9->mgm==1.0.0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from gradio_client==0.2.9->mgm==1.0.0) (4.12.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->mgm==1.0.0) (2024.12.14)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx==0.24.0->mgm==1.0.0)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->mgm==1.0.0) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->mgm==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0->mgm==1.0.0) (0.5.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->mgm==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->mgm==1.0.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->mgm==1.0.0) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->mgm==1.0.0) (3.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->mgm==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->mgm==1.0.0) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2->mgm==1.0.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2->mgm==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->mgm==1.0.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->mgm==1.0.0) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->mgm==1.0.0) (3.31.4)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->mgm==1.0.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->mgm==1.0.0) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->mgm==1.0.0) (0.14.0)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi->mgm==1.0.0)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting wavedrom (from markdown2[all]->mgm==1.0.0)\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting latex2mathml (from markdown2[all]->mgm==1.0.0)\n",
            "  Downloading latex2mathml-3.77.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->mgm==1.0.0) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->mgm==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair>=4.2.0->gradio==3.35.2->mgm==1.0.0) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair>=4.2.0->gradio==3.35.2->mgm==1.0.0) (1.23.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.0->mgm==1.0.0) (3.7.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->mgm==1.0.0) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->mgm==1.0.0) (2.0.3)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.35.2->mgm==1.0.0)\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: pip is still looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.35.2->mgm==1.0.0)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.35.2->mgm==1.0.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.35.2->mgm==1.0.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.35.2->mgm==1.0.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.35.2->mgm==1.0.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.35.2->mgm==1.0.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.35.2->mgm==1.0.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.35.2->mgm==1.0.0) (1.18.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gradio==3.35.2->mgm==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gradio==3.35.2->mgm==1.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gradio==3.35.2->mgm==1.0.0) (4.55.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gradio==3.35.2->mgm==1.0.0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gradio==3.35.2->mgm==1.0.0) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gradio==3.35.2->mgm==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->gradio==3.35.2->mgm==1.0.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->gradio==3.35.2->mgm==1.0.0) (2025.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->mgm==1.0.0) (1.3.0)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->mgm==1.0.0)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from wavedrom->markdown2[all]->mgm==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->mgm==1.0.0) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->mgm==1.0.0) (0.36.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->mgm==1.0.0) (0.22.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->mgm==1.0.0) (1.0.3)\n",
            "Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "Downloading bitsandbytes-0.41.0-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "Downloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
            "Downloading gradio-3.35.2-py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.2.9-py3-none-any.whl (288 kB)\n",
            "Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "Downloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
            "Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m125.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-1.10.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "Downloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
            "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
            "Downloading markdown2-2.5.3-py3-none-any.whl (48 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "Building wheels for collected packages: mgm, wavedrom\n",
            "  Building editable for mgm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mgm: filename=mgm-1.0.0-0.editable-py3-none-any.whl size=14363 sha256=db3953f33c929781922f3a49d02d62e7c9189d32620ac8374ffd87c7350d6426\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vb5b673d/wheels/67/e1/1e/3cf5fe05eb062644ebd3754ec25075ecf914ec3a7c9ac857b1\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=1e699fc3346de6d90b957bcad7b9c77ee681a9cbd771d5148a621f4cec87e281\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/cf/3b/4dcf6b22fa41c5ece715fa5f4e05afd683e7b0ce0f2fcc7bb6\n",
            "Successfully built mgm wavedrom\n",
            "Installing collected packages: sentencepiece, pydub, lit, bitsandbytes, uvicorn, svgwrite, shortuuid, semantic-version, python-multipart, pydantic, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, markdown2, markdown-it-py, latex2mathml, ffmpy, einops, aiofiles, wavedrom, starlette, scikit-learn, nvidia-cusolver-cu11, nvidia-cudnn-cu11, mdit-py-plugins, httpcore, einops-exts, tokenizers, httpx, fastapi, transformers, gradio_client, gradio, triton, torch, torchvision, accelerate, timm, peft, mgm\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.0\n",
            "    Uninstalling sentencepiece-0.2.0:\n",
            "      Successfully uninstalled sentencepiece-0.2.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.5\n",
            "    Uninstalling pydantic-2.10.5:\n",
            "      Successfully uninstalled pydantic-2.10.5\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: mdit-py-plugins\n",
            "    Found existing installation: mdit-py-plugins 0.4.2\n",
            "    Uninstalling mdit-py-plugins-0.4.2:\n",
            "      Successfully uninstalled mdit-py-plugins-0.4.2\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.2.1\n",
            "    Uninstalling accelerate-1.2.1:\n",
            "      Successfully uninstalled accelerate-1.2.1\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.14\n",
            "    Uninstalling timm-1.0.14:\n",
            "      Successfully uninstalled timm-1.0.14\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.10.21 which is incompatible.\n",
            "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "langchain 0.3.15 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.21 which is incompatible.\n",
            "google-genai 0.3.0 requires pydantic<3.0.0dev,>=2.0.0, but you have pydantic 1.10.21 which is incompatible.\n",
            "wandb 0.19.4 requires pydantic<3,>=2.6, but you have pydantic 1.10.21 which is incompatible.\n",
            "langchain-core 0.3.31 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.21 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.21.0 aiofiles-24.1.0 bitsandbytes-0.41.0 einops-0.6.1 einops-exts-0.0.4 fastapi-0.115.7 ffmpy-0.5.0 gradio-3.35.2 gradio_client-0.2.9 httpcore-0.17.3 httpx-0.24.0 latex2mathml-3.77.0 lit-18.1.8 markdown-it-py-2.2.0 markdown2-2.5.3 mdit-py-plugins-0.3.3 mgm-1.0.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 peft-0.4.0 pydantic-1.10.21 pydub-0.25.1 python-multipart-0.0.20 scikit-learn-1.2.2 semantic-version-2.10.0 sentencepiece-0.1.99 shortuuid-1.0.13 starlette-0.45.3 svgwrite-1.4.3 timm-0.9.16 tokenizers-0.15.0 torch-2.0.1 torchvision-0.15.2 transformers-4.36.2 triton-2.0.0 uvicorn-0.34.0 wavedrom-2.0.3.post3\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDt-ZrvUkjbx",
        "outputId": "c08cb45a-eb1d-4d23-b885-814899f54be2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Installing collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.3\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.3.tar.gz (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.0.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash-attn) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash-attn) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->flash-attn) (3.31.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->flash-attn) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for flash-attn\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for flash-attn\n",
            "Failed to build flash-attn\n",
            "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (flash-attn)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install ninja\n",
        "!pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SezhXvCTvhL9"
      },
      "outputs": [],
      "source": [
        "!mkdir work_dirs\n",
        "!mkdir model_zoo\n",
        "!mkdir model_zoo/LLM\n",
        "!mkdir model_zoo/LLM/vicuna\n",
        "!mkdir model_zoo/OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARdWsdyek1ma",
        "outputId": "b3b579b7-e379-4a33-f0f8-7da53dd8d0e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'work_dirs/MGM/MGM-13B-HD'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Total 30 (delta 0), reused 0 (delta 0), pack-reused 30 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (30/30), 202.20 KiB | 5.62 MiB/s, done.\n",
            "Filtering content: 100% (8/8), 5.24 GiB | 21.51 MiB/s, done.\n",
            "Encountered 5 file(s) that may not have been copied correctly on Windows:\n",
            "\tmodel-00004-of-00006.safetensors\n",
            "\tmodel-00001-of-00006.safetensors\n",
            "\tmodel-00003-of-00006.safetensors\n",
            "\tmodel-00002-of-00006.safetensors\n",
            "\tmodel-00005-of-00006.safetensors\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/YanweiLi/MGM-13B-HD work_dirs/MGM/MGM-13B-HD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d62SiUpKVQ32",
        "outputId": "6e91375b-fc3f-42d4-dd0e-e0d9baee7196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting open-clip-torch\n",
            "  Downloading open_clip_torch-2.30.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (2.0.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.15.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (2024.11.6)\n",
            "Collecting ftfy (from open-clip-torch)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.5.2)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.9.16)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9.0->open-clip-torch) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9.0->open-clip-torch) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.9.0->open-clip-torch) (3.31.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.9.0->open-clip-torch) (18.1.8)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open-clip-torch) (0.2.13)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->open-clip-torch) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->open-clip-torch) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->open-clip-torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.9.0->open-clip-torch) (1.3.0)\n",
            "Downloading open_clip_torch-2.30.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "Installing collected packages: ftfy, open-clip-torch\n",
            "Successfully installed ftfy-6.3.1 open-clip-torch-2.30.0\n"
          ]
        }
      ],
      "source": [
        "!pip install open-clip-torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqsCxna2Bf-o",
        "outputId": "37e542d7-d951-48fd-c986-c5f078de1a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'model_zoo/LLM/vicuna'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 44 (delta 0), reused 0 (delta 0), pack-reused 40 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (44/44), 9.70 KiB | 902.00 KiB/s, done.\n",
            "Filtering content: 100% (4/4), 4.24 GiB | 21.52 MiB/s, done.\n",
            "Encountered 3 file(s) that may not have been copied correctly on Windows:\n",
            "\tpytorch_model-00003-of-00003.bin\n",
            "\tpytorch_model-00002-of-00003.bin\n",
            "\tpytorch_model-00001-of-00003.bin\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/lmsys/vicuna-13b-v1.5 model_zoo/LLM/vicuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wcWpSYH9qOkD"
      },
      "outputs": [],
      "source": [
        "# !git clone https://huggingface.co/lmsys/vicuna-7b-v1.5 model_zoo/LLM/vicuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wXdMSBdBeLZa",
        "outputId": "ca04ba93-ef70-4dce-9cf3-c6c09ea273c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'model_zoo/OpenAI/clip-vit-large-patch14-336'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Total 27 (delta 0), reused 0 (delta 0), pack-reused 27 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (27/27), 1.07 MiB | 1.48 MiB/s, done.\n",
            "Filtering content: 100% (2/2), 3.18 GiB | 97.30 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/openai/clip-vit-large-patch14-336 model_zoo/OpenAI/clip-vit-large-patch14-336"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vgzoaY4oePXT",
        "outputId": "d7fbd2b9-628b-470d-ab0d-5a845c1815e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'model_zoo/OpenAI/openclip-convnext-large-d-320-laion2B-s29B-b131K-ft-soup'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 36 (delta 1), reused 0 (delta 0), pack-reused 31 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (36/36), 1.07 MiB | 1.28 MiB/s, done.\n",
            "Filtering content: 100% (5/5), 2.63 GiB | 116.27 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup model_zoo/OpenAI/openclip-convnext-large-d-320-laion2B-s29B-b131K-ft-soup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OJBqMu4ClXfW",
        "outputId": "31fda6e3-17b5-4790-a502-d7f0f20535de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.16.3.tar.gz (1.4 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepspeed) (0.6.1)\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.11.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed) (9.0.0)\n",
            "Collecting pydantic>=2.0.0 (from deepspeed)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from deepspeed) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepspeed) (4.67.1)\n",
            "Collecting nvidia-ml-py (from deepspeed)\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deepspeed) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deepspeed) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->deepspeed) (3.31.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->deepspeed) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->deepspeed) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
            "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.16.3-py3-none-any.whl size=1550052 sha256=48d61905af6d0991fd0b77c3a814545e4f5f764b9a53f0b086a00691c44019da\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/dc/d4/7e7e07b11bc7c0e2a1a495b967acf58de61261eed4596fb23b\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: nvidia-ml-py, hjson, pydantic, deepspeed\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.21\n",
            "    Uninstalling pydantic-1.10.21:\n",
            "      Successfully uninstalled pydantic-1.10.21\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mgm 1.0.0 requires pydantic<2,>=1, but you have pydantic 2.10.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deepspeed-0.16.3 hjson-3.1.0 nvidia-ml-py-12.570.86 pydantic-2.10.6\n"
          ]
        }
      ],
      "source": [
        "!pip install deepspeed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QXGiDbssk0Cl",
        "outputId": "a3a3d56b-4acc-4112-d7dc-53fcba0b7409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting diffusers==0.26.3\n",
            "  Downloading diffusers-0.26.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.26.3) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.26.3) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.26.3) (0.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.26.3) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.26.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.26.3) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.26.3) (0.5.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.26.3) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.26.3) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.26.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.26.3) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.26.3) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.26.3) (4.12.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.26.3) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.26.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.26.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.26.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.26.3) (2024.12.14)\n",
            "Downloading diffusers-0.26.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.19.0\n",
            "    Uninstalling diffusers-0.19.0:\n",
            "      Successfully uninstalled diffusers-0.19.0\n",
            "Successfully installed diffusers-0.26.3\n"
          ]
        }
      ],
      "source": [
        "!pip install diffusers==0.26.3\n",
        "# !pip install paddleocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RAo8fCIAKkpi"
      },
      "outputs": [],
      "source": [
        "code = \"\"\"\n",
        "\n",
        "import argparse\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "\n",
        "from mgm.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
        "from mgm.conversation import conv_templates, SeparatorStyle\n",
        "from mgm.model.builder import load_pretrained_model\n",
        "from mgm.utils import disable_torch_init\n",
        "from mgm.mm_utils import process_images, tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from transformers import TextStreamer\n",
        "try:\n",
        "    from diffusers import DiffusionPipeline\n",
        "except:\n",
        "    print('please install diffusers==0.26.3')\n",
        "\n",
        "try:\n",
        "    from paddleocr import PaddleOCR\n",
        "except:\n",
        "    print('please install paddleocr following https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/README_en.md')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main(model_path='work_dirs/MGM/MGM-13B-HD', model_base=None, image_file=None, device='cuda', conv_mode1=None, temperature=0.2, max_new_tokens=512, load_8bit=False, load_4bit=False, ocr=False, gen=True, output_file='generate.png', debug=False):\n",
        "    # Model\n",
        "    disable_torch_init()\n",
        "\n",
        "    if gen:\n",
        "        pipe = DiffusionPipeline.from_pretrained(\n",
        "            \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\"\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "    model_name = get_model_name_from_path(model_path)\n",
        "    tokenizer, model, image_processor, context_len = load_pretrained_model(model_path, model_base, model_name, load_8bit, load_4bit, device=device)\n",
        "\n",
        "    if '8x7b' in model_name.lower():\n",
        "        conv_mode = \"mistral_instruct\"\n",
        "    elif '34b' in model_name.lower():\n",
        "        conv_mode = \"chatml_direct\"\n",
        "    elif '2b' in model_name.lower():\n",
        "        conv_mode = \"gemma\"\n",
        "    else:\n",
        "        conv_mode = \"vicuna_v1\"\n",
        "\n",
        "    llm_prompts =[]\n",
        "    conv = conv_templates[conv_mode].copy()\n",
        "    if \"mpt\" in model_name.lower():\n",
        "        roles = ('user', 'assistant')\n",
        "    else:\n",
        "        roles = conv.roles\n",
        "\n",
        "\n",
        "\n",
        "    images = None\n",
        "    image_tensor = None\n",
        "    image_tensor_aux = []\n",
        "\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            inp = input(f\"{roles[0]}: \")\n",
        "        except EOFError:\n",
        "            inp = \"\"\n",
        "        if not inp:\n",
        "            print(\"exit...\")\n",
        "            break\n",
        "\n",
        "        print(f\"{roles[1]}: \", end=\"\")\n",
        "        if gen:\n",
        "            inp = inp + ' <GEN>'\n",
        "        # print(inp, '====')\n",
        "\n",
        "        conv.append_message(conv.roles[0], inp)\n",
        "        conv.append_message(conv.roles[1], None)\n",
        "        prompt = conv.get_prompt()\n",
        "\n",
        "        input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).to('cuda')\n",
        "        streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            output_ids = model.generate(\n",
        "                input_ids,\n",
        "                images=image_tensor,\n",
        "                images_aux=image_tensor_aux if len(image_tensor_aux)>0 else None,\n",
        "                do_sample=True if temperature > 0 else False,\n",
        "                temperature=temperature,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                bos_token_id=tokenizer.bos_token_id,  # Begin of sequence token\n",
        "                eos_token_id=tokenizer.eos_token_id,  # End of sequence token\n",
        "                pad_token_id=tokenizer.pad_token_id,  # Pad token\n",
        "                streamer=streamer,\n",
        "                use_cache=True)\n",
        "\n",
        "        outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
        "        conv.messages[-1][-1] = outputs\n",
        "\n",
        "        if gen and '<h>' in outputs and '</h>' in outputs:\n",
        "            common_neg_prompt = \"out of frame, lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature\"\n",
        "            prompt = outputs.split(\"</h>\")[-2].split(\"<h>\")[-1]\n",
        "            llm_prompts.append(prompt)\n",
        "        #     output_img = pipe(prompt, negative_prompt=common_neg_prompt).images[0]\n",
        "        #     output_img.save(args.output_file)\n",
        "        #     print(f'Generate an image, save at {args.output_file}')\n",
        "\n",
        "    return llm_prompts\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    prompts = main()\n",
        "    with open(f\"llm_prompts.txt\", \"w\") as f:\n",
        "        f.write(str(prompts))\n",
        "    f.close()\n",
        "    print(prompts)\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "awuATKnx7b9X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.remove(f'mgm/serve/cli.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TuzgXG757dpR"
      },
      "outputs": [],
      "source": [
        "with open(f'mgm/serve/cli.py', 'w') as f:\n",
        "    f.write(code)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gTMSV-vYdDPl",
        "outputId": "78341a5e-b73e-4b56-823c-475d17ef3e52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting diffusers==0.19.0\n",
            "  Using cached diffusers-0.19.0-py3-none-any.whl\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.0) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.0) (0.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.0) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.0) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.0) (0.5.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.19.0) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.19.0) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.19.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.19.0) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.19.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.19.0) (4.12.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers==0.19.0) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.19.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.19.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.19.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.19.0) (2024.12.14)\n",
            "Installing collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.26.3\n",
            "    Uninstalling diffusers-0.26.3:\n",
            "      Successfully uninstalled diffusers-0.26.3\n",
            "Successfully installed diffusers-0.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install diffusers==0.19.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxuokEuinrKz"
      },
      "outputs": [],
      "source": [
        "!python -m mgm.serve.cli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCgudyUZDvkr",
        "outputId": "5aa3c8a7-eb0f-4e79-e34c-c27552782314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'StoryDiffusion'...\n",
            "remote: Enumerating objects: 312, done.\u001b[K\n",
            "remote: Counting objects: 100% (151/151), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 312 (delta 117), reused 86 (delta 84), pack-reused 161 (from 1)\u001b[K\n",
            "Receiving objects: 100% (312/312), 22.76 MiB | 41.91 MiB/s, done.\n",
            "Resolving deltas: 100% (164/164), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HVision-NKU/StoryDiffusion.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iSpK-xiJw7a",
        "outputId": "1b43798f-78e1-41eb-86ec-8b9dd255c522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/StoryDiffusion\n"
          ]
        }
      ],
      "source": [
        "%cd StoryDiffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wogkg9M2HXZ-",
        "outputId": "12ce97a1-d59b-4a5a-b8b0-39de124477b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio==4.22.0 (from -r requirements.txt (line 1))\n",
            "  Downloading gradio-4.22.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting xformers==0.0.20 (from -r requirements.txt (line 2))\n",
            "  Downloading xformers-0.0.20-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting torch==2.0.1 (from -r requirements.txt (line 3))\n",
            "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.15.2 (from -r requirements.txt (line 4))\n",
            "  Downloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting diffusers==0.25.0 (from -r requirements.txt (line 5))\n",
            "  Downloading diffusers-0.25.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting transformers==4.36.2 (from -r requirements.txt (line 6))\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub==0.20.2 (from -r requirements.txt (line 7))\n",
            "  Downloading huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting spaces==0.19.4 (from -r requirements.txt (line 8))\n",
            "  Downloading spaces-0.19.4-py3-none-any.whl.metadata (972 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.26.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.5.2)\n",
            "Collecting omegaconf (from -r requirements.txt (line 12))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.14.0)\n",
            "Collecting httpx==0.27.0 (from -r requirements.txt (line 14))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting safetensors (from -r requirements.txt (line 11))\n",
            "  Downloading safetensors-0.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.22.0->-r requirements.txt (line 1)) (5.5.0)\n",
            "Collecting fastapi (from gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==0.13.0 (from gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading gradio_client-0.13.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.22.0->-r requirements.txt (line 1)) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.22.0->-r requirements.txt (line 1)) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.22.0->-r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.22.0->-r requirements.txt (line 1)) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==4.22.0->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.22.0->-r requirements.txt (line 1)) (2.2.2)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.22.0->-r requirements.txt (line 1)) (2.10.6)\n",
            "Collecting pydub (from gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.22.0->-r requirements.txt (line 1)) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.9 in /usr/local/lib/python3.11/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.22.0->-r requirements.txt (line 1)) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.22.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pyre-extensions==0.0.29 (from xformers==0.0.20->-r requirements.txt (line 2))\n",
            "  Downloading pyre_extensions-0.0.29-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->-r requirements.txt (line 3)) (3.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->-r requirements.txt (line 3)) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->-r requirements.txt (line 5)) (8.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->-r requirements.txt (line 5)) (2024.11.6)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2->-r requirements.txt (line 6))\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2->-r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.20.2->-r requirements.txt (line 7)) (2024.10.0)\n",
            "Requirement already satisfied: psutil<6,>=2 in /usr/local/lib/python3.11/dist-packages (from spaces==0.19.4->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0->-r requirements.txt (line 14)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0->-r requirements.txt (line 14)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0->-r requirements.txt (line 14)) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0->-r requirements.txt (line 14)) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.0->-r requirements.txt (line 14)) (1.3.1)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.13.0->gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.27.0->-r requirements.txt (line 14)) (0.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 3)) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 3)) (0.45.1)\n",
            "Collecting typing-inspect (from pyre-extensions==0.0.29->xformers==0.0.20->-r requirements.txt (line 2))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 3)) (3.31.4)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 3))\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is looking at multiple versions of accelerate to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting accelerate (from -r requirements.txt (line 10))\n",
            "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading accelerate-1.1.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading accelerate-1.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
            "INFO: pip is still looking at multiple versions of accelerate to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading accelerate-0.34.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading accelerate-0.34.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 12))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of peft to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting peft (from -r requirements.txt (line 13))\n",
            "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.22.0->-r requirements.txt (line 1)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.22.0->-r requirements.txt (line 1)) (1.25.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.22.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.22.0->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.22.0->-r requirements.txt (line 1)) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.22.0->-r requirements.txt (line 1)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.22.0->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.22.0->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.22.0->-r requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.22.0->-r requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.22.0->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.22.0->-r requirements.txt (line 1)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2->-r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.22.0->-r requirements.txt (line 1)) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.22.0->-r requirements.txt (line 1)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.22.0->-r requirements.txt (line 1)) (13.9.4)\n",
            "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting starlette<0.46.0,>=0.40.0 (from fastapi->gradio==4.22.0->-r requirements.txt (line 1))\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.25.0->-r requirements.txt (line 5)) (3.21.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.22.0->-r requirements.txt (line 1)) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.22.0->-r requirements.txt (line 1)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.22.0->-r requirements.txt (line 1)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.22.0->-r requirements.txt (line 1)) (0.22.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.22.0->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.22.0->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.22.0->-r requirements.txt (line 1)) (2.18.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyre-extensions==0.0.29->xformers==0.0.20->-r requirements.txt (line 2))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio==4.22.0->-r requirements.txt (line 1)) (0.1.2)\n",
            "Downloading gradio-4.22.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.20-cp311-cp311-manylinux2014_x86_64.whl (109.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diffusers-0.25.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spaces-0.19.4-py3-none-any.whl (15 kB)\n",
            "Downloading safetensors-0.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.13.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyre_extensions-0.0.29-py3-none-any.whl (12 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=2afe5f3a826a726aaea3bcda7d88ae65bf8162141d311a6a9ef6f29d34377e01\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: pydub, lit, antlr4-python3-runtime, websockets, uvicorn, tomlkit, semantic-version, safetensors, ruff, python-multipart, pillow, omegaconf, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, mypy-extensions, markupsafe, ffmpy, aiofiles, typing-inspect, starlette, nvidia-cusolver-cu11, nvidia-cudnn-cu11, huggingface-hub, httpx, tokenizers, pyre-extensions, gradio-client, fastapi, diffusers, transformers, gradio, spaces, triton, torch, accelerate, xformers, torchvision, peft\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 14.2\n",
            "    Uninstalling websockets-14.2:\n",
            "      Successfully uninstalled websockets-14.2\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.5.2\n",
            "    Uninstalling safetensors-0.5.2:\n",
            "      Successfully uninstalled safetensors-0.5.2\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.28.1\n",
            "    Uninstalling huggingface-hub-0.28.1:\n",
            "      Successfully uninstalled huggingface-hub-0.28.1\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.32.2\n",
            "    Uninstalling diffusers-0.32.2:\n",
            "      Successfully uninstalled diffusers-0.32.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.2\n",
            "    Uninstalling transformers-4.48.2:\n",
            "      Successfully uninstalled transformers-4.48.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.3.0\n",
            "    Uninstalling accelerate-1.3.0:\n",
            "      Successfully uninstalled accelerate-1.3.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "google-genai 0.8.0 requires websockets<15.0dev,>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.32.1 aiofiles-23.2.1 antlr4-python3-runtime-4.9.3 diffusers-0.25.0 fastapi-0.115.8 ffmpy-0.5.0 gradio-4.22.0 gradio-client-0.13.0 httpx-0.27.0 huggingface-hub-0.20.2 lit-18.1.8 markupsafe-2.1.5 mypy-extensions-1.0.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 omegaconf-2.3.0 peft-0.13.2 pillow-10.4.0 pydub-0.25.1 pyre-extensions-0.0.29 python-multipart-0.0.20 ruff-0.9.6 safetensors-0.4.0 semantic-version-2.10.0 spaces-0.19.4 starlette-0.45.3 tokenizers-0.15.2 tomlkit-0.12.0 torch-2.0.1 torchvision-0.15.2 transformers-4.36.2 triton-2.0.0 typing-inspect-0.9.0 uvicorn-0.34.0 websockets-11.0.3 xformers-0.0.20\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "38abcb91cd0c4da3af9041664e3b6fcf",
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kS82U-gZH34",
        "outputId": "5274387d-d463-498e-9354-40ad880b0e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.20.2)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2024.12.14)\n",
            "Downloading huggingface_hub-0.28.0-py3-none-any.whl (464 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.1/464.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface_hub\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.20.2\n",
            "    Uninstalling huggingface-hub-0.20.2:\n",
            "      Successfully uninstalled huggingface-hub-0.20.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface_hub-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVUzYsshdBCX",
        "outputId": "d858726d-3c3b-4621-ba26-44bf6f4f1860"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/MGM\n"
          ]
        }
      ],
      "source": [
        "%cd MGM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzLF2Q2DI6vx"
      },
      "outputs": [],
      "source": [
        "with open(f'llm_prompts.txt', 'r') as f:\n",
        "    llm_prompts = f.read()\n",
        "    llm_prompts = eval(llm_prompts)\n",
        "    print(llm_prompts)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhjknikJoBxA",
        "outputId": "f21b08a2-8152-4643-97ec-198cdd5f7985"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/StoryDiffusion\n"
          ]
        }
      ],
      "source": [
        "%cd StoryDiffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhZXzc4yE8GT",
        "outputId": "624c44dd-ce87-4594-c611-9c3668693249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting huggingface-hub==0.25.2\n",
            "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.25.2) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.25.2) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.25.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.25.2) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.25.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.25.2) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.25.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.25.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.25.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.25.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.25.2) (2025.1.31)\n",
            "Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.6/436.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.2\n",
            "    Uninstalling huggingface-hub-0.20.2:\n",
            "      Successfully uninstalled huggingface-hub-0.20.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.25.2\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface-hub==0.25.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1Y4MAT2GS-F"
      },
      "outputs": [],
      "source": [
        "# %load_ext autoreload\n",
        "# %autoreload 2\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "import requests\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "from datetime import datetime\n",
        "from utils.gradio_utils import is_torch2_available\n",
        "if is_torch2_available():\n",
        "    from utils.gradio_utils import \\\n",
        "        AttnProcessor2_0 as AttnProcessor\n",
        "else:\n",
        "    from utils.gradio_utils  import AttnProcessor\n",
        "\n",
        "import diffusers\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "from diffusers import DDIMScheduler\n",
        "import torch.nn.functional as F\n",
        "from utils.gradio_utils import cal_attn_mask_xl\n",
        "import copy\n",
        "import os\n",
        "from diffusers.utils import load_image\n",
        "from utils.utils import get_comic\n",
        "from utils.style_template import styles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_nnOFbhGS-I"
      },
      "outputs": [],
      "source": [
        "## Global\n",
        "STYLE_NAMES = list(styles.keys())\n",
        "DEFAULT_STYLE_NAME = \"(No style)\"\n",
        "MAX_SEED = np.iinfo(np.int32).max\n",
        "global models_dict\n",
        "use_va = False\n",
        "models_dict = {\n",
        "   \"Juggernaut\":\"RunDiffusion/Juggernaut-XL-v8\",\n",
        "   \"RealVision\":\"SG161222/RealVisXL_V4.0\" ,\n",
        "   \"SDXL\":\"stabilityai/stable-diffusion-xl-base-1.0\" ,\n",
        "   \"Unstable\": \"stablediffusionapi/sdxl-unstable-diffusers-y\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bG_2_CDGS-I",
        "outputId": "39b1fe3a-6b29-4f8f-96ad-6b6536c04ca1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEbOzQuDGS-K"
      },
      "outputs": [],
      "source": [
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "#################################################\n",
        "########Consistent Self-Attention################\n",
        "#################################################\n",
        "class SpatialAttnProcessor2_0(torch.nn.Module):\n",
        "    r\"\"\"\n",
        "    Attention processor for IP-Adapater for PyTorch 2.0.\n",
        "    Args:\n",
        "        hidden_size (`int`):\n",
        "            The hidden size of the attention layer.\n",
        "        cross_attention_dim (`int`):\n",
        "            The number of channels in the `encoder_hidden_states`.\n",
        "        text_context_len (`int`, defaults to 77):\n",
        "            The context length of the text features.\n",
        "        scale (`float`, defaults to 1.0):\n",
        "            the weight scale of image prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size = None, cross_attention_dim=None,id_length = 4,device = \"cuda\",dtype = torch.float16):\n",
        "        super().__init__()\n",
        "        if not hasattr(F, \"scaled_dot_product_attention\"):\n",
        "            raise ImportError(\"AttnProcessor2_0 requires PyTorch 2.0, to use it, please upgrade PyTorch to 2.0.\")\n",
        "        self.device = device\n",
        "        self.dtype = dtype\n",
        "        self.hidden_size = hidden_size\n",
        "        self.cross_attention_dim = cross_attention_dim\n",
        "        self.total_length = id_length + 1\n",
        "        self.id_length = id_length\n",
        "        self.id_bank = {}\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        attn,\n",
        "        hidden_states,\n",
        "        encoder_hidden_states=None,\n",
        "        attention_mask=None,\n",
        "        temb=None):\n",
        "        global total_count,attn_count,cur_step,mask1024,mask4096\n",
        "        global sa32, sa64\n",
        "        global write\n",
        "        global height,width\n",
        "        if write:\n",
        "            # print(f\"white:{cur_step}\")\n",
        "            self.id_bank[cur_step] = [hidden_states[:self.id_length], hidden_states[self.id_length:]]\n",
        "        else:\n",
        "            encoder_hidden_states = torch.cat((self.id_bank[cur_step][0].to(self.device),hidden_states[:1],self.id_bank[cur_step][1].to(self.device),hidden_states[1:]))\n",
        "        # skip in early step\n",
        "        if cur_step <5:\n",
        "            hidden_states = self.__call2__(attn, hidden_states,encoder_hidden_states,attention_mask,temb)\n",
        "        else:   # 256 1024 4096\n",
        "            random_number = random.random()\n",
        "            if cur_step <20:\n",
        "                rand_num = 0.3\n",
        "            else:\n",
        "                rand_num = 0.1\n",
        "            if random_number > rand_num:\n",
        "                if not write:\n",
        "                    if hidden_states.shape[1] == (height//32) * (width//32):\n",
        "                        attention_mask = mask1024[mask1024.shape[0] // self.total_length * self.id_length:]\n",
        "                    else:\n",
        "                        attention_mask = mask4096[mask4096.shape[0] // self.total_length * self.id_length:]\n",
        "                else:\n",
        "                    if hidden_states.shape[1] == (height//32) * (width//32):\n",
        "                        attention_mask = mask1024[:mask1024.shape[0] // self.total_length * self.id_length,:mask1024.shape[0] // self.total_length * self.id_length]\n",
        "                    else:\n",
        "                        attention_mask = mask4096[:mask4096.shape[0] // self.total_length * self.id_length,:mask4096.shape[0] // self.total_length * self.id_length]\n",
        "                hidden_states = self.__call1__(attn, hidden_states,encoder_hidden_states,attention_mask,temb)\n",
        "            else:\n",
        "                hidden_states = self.__call2__(attn, hidden_states,None,attention_mask,temb)\n",
        "        attn_count +=1\n",
        "        if attn_count == total_count:\n",
        "            attn_count = 0\n",
        "            cur_step += 1\n",
        "            mask1024,mask4096 = cal_attn_mask_xl(self.total_length,self.id_length,sa32,sa64,height,width, device=self.device, dtype= self.dtype)\n",
        "\n",
        "        return hidden_states\n",
        "    def __call1__(\n",
        "        self,\n",
        "        attn,\n",
        "        hidden_states,\n",
        "        encoder_hidden_states=None,\n",
        "        attention_mask=None,\n",
        "        temb=None,\n",
        "    ):\n",
        "        residual = hidden_states\n",
        "        if attn.spatial_norm is not None:\n",
        "            hidden_states = attn.spatial_norm(hidden_states, temb)\n",
        "        input_ndim = hidden_states.ndim\n",
        "\n",
        "        if input_ndim == 4:\n",
        "            total_batch_size, channel, height, width = hidden_states.shape\n",
        "            hidden_states = hidden_states.view(total_batch_size, channel, height * width).transpose(1, 2)\n",
        "        total_batch_size,nums_token,channel = hidden_states.shape\n",
        "        img_nums = total_batch_size//2\n",
        "        hidden_states = hidden_states.view(-1,img_nums,nums_token,channel).reshape(-1,img_nums * nums_token,channel)\n",
        "\n",
        "        batch_size, sequence_length, _ = hidden_states.shape\n",
        "\n",
        "        if attn.group_norm is not None:\n",
        "            hidden_states = attn.group_norm(hidden_states.transpose(1, 2)).transpose(1, 2)\n",
        "\n",
        "        query = attn.to_q(hidden_states)\n",
        "\n",
        "        if encoder_hidden_states is None:\n",
        "            encoder_hidden_states = hidden_states  # B, N, C\n",
        "        else:\n",
        "            encoder_hidden_states = encoder_hidden_states.view(-1,self.id_length+1,nums_token,channel).reshape(-1,(self.id_length+1) * nums_token,channel)\n",
        "\n",
        "        key = attn.to_k(encoder_hidden_states)\n",
        "        value = attn.to_v(encoder_hidden_states)\n",
        "\n",
        "\n",
        "        inner_dim = key.shape[-1]\n",
        "        head_dim = inner_dim // attn.heads\n",
        "\n",
        "        query = query.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
        "\n",
        "        key = key.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
        "        value = value.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
        "        hidden_states = F.scaled_dot_product_attention(\n",
        "            query, key, value, attn_mask=attention_mask, dropout_p=0.0, is_causal=False\n",
        "        )\n",
        "\n",
        "        hidden_states = hidden_states.transpose(1, 2).reshape(total_batch_size, -1, attn.heads * head_dim)\n",
        "        hidden_states = hidden_states.to(query.dtype)\n",
        "\n",
        "\n",
        "\n",
        "        # linear proj\n",
        "        hidden_states = attn.to_out[0](hidden_states)\n",
        "        # dropout\n",
        "        hidden_states = attn.to_out[1](hidden_states)\n",
        "\n",
        "\n",
        "        if input_ndim == 4:\n",
        "            hidden_states = hidden_states.transpose(-1, -2).reshape(total_batch_size, channel, height, width)\n",
        "        if attn.residual_connection:\n",
        "            hidden_states = hidden_states + residual\n",
        "        hidden_states = hidden_states / attn.rescale_output_factor\n",
        "        # print(hidden_states.shape)\n",
        "        return hidden_states\n",
        "    def __call2__(\n",
        "        self,\n",
        "        attn,\n",
        "        hidden_states,\n",
        "        encoder_hidden_states=None,\n",
        "        attention_mask=None,\n",
        "        temb=None):\n",
        "        residual = hidden_states\n",
        "\n",
        "        if attn.spatial_norm is not None:\n",
        "            hidden_states = attn.spatial_norm(hidden_states, temb)\n",
        "\n",
        "        input_ndim = hidden_states.ndim\n",
        "\n",
        "        if input_ndim == 4:\n",
        "            batch_size, channel, height, width = hidden_states.shape\n",
        "            hidden_states = hidden_states.view(batch_size, channel, height * width).transpose(1, 2)\n",
        "\n",
        "        batch_size, sequence_length, channel = (\n",
        "            hidden_states.shape\n",
        "        )\n",
        "        # print(hidden_states.shape)\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = attn.prepare_attention_mask(attention_mask, sequence_length, batch_size)\n",
        "            # scaled_dot_product_attention expects attention_mask shape to be\n",
        "            # (batch, heads, source_length, target_length)\n",
        "            attention_mask = attention_mask.view(batch_size, attn.heads, -1, attention_mask.shape[-1])\n",
        "\n",
        "        if attn.group_norm is not None:\n",
        "            hidden_states = attn.group_norm(hidden_states.transpose(1, 2)).transpose(1, 2)\n",
        "\n",
        "        query = attn.to_q(hidden_states)\n",
        "\n",
        "        if encoder_hidden_states is None:\n",
        "            encoder_hidden_states = hidden_states  # B, N, C\n",
        "        else:\n",
        "            encoder_hidden_states = encoder_hidden_states.view(-1,self.id_length+1,sequence_length,channel).reshape(-1,(self.id_length+1) * sequence_length,channel)\n",
        "\n",
        "        key = attn.to_k(encoder_hidden_states)\n",
        "        value = attn.to_v(encoder_hidden_states)\n",
        "\n",
        "        inner_dim = key.shape[-1]\n",
        "        head_dim = inner_dim // attn.heads\n",
        "\n",
        "        query = query.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
        "\n",
        "        key = key.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
        "        value = value.view(batch_size, -1, attn.heads, head_dim).transpose(1, 2)\n",
        "\n",
        "        hidden_states = F.scaled_dot_product_attention(\n",
        "            query, key, value, attn_mask=attention_mask, dropout_p=0.0, is_causal=False\n",
        "        )\n",
        "\n",
        "        hidden_states = hidden_states.transpose(1, 2).reshape(batch_size, -1, attn.heads * head_dim)\n",
        "        hidden_states = hidden_states.to(query.dtype)\n",
        "\n",
        "        # linear proj\n",
        "        hidden_states = attn.to_out[0](hidden_states)\n",
        "        # dropout\n",
        "        hidden_states = attn.to_out[1](hidden_states)\n",
        "\n",
        "        if input_ndim == 4:\n",
        "            hidden_states = hidden_states.transpose(-1, -2).reshape(batch_size, channel, height, width)\n",
        "\n",
        "        if attn.residual_connection:\n",
        "            hidden_states = hidden_states + residual\n",
        "\n",
        "        hidden_states = hidden_states / attn.rescale_output_factor\n",
        "\n",
        "        return hidden_states\n",
        "\n",
        "def set_attention_processor(unet,id_length):\n",
        "    attn_procs = {}\n",
        "    for name in unet.attn_processors.keys():\n",
        "        cross_attention_dim = None if name.endswith(\"attn1.processor\") else unet.config.cross_attention_dim\n",
        "        if name.startswith(\"mid_block\"):\n",
        "            hidden_size = unet.config.block_out_channels[-1]\n",
        "        elif name.startswith(\"up_blocks\"):\n",
        "            block_id = int(name[len(\"up_blocks.\")])\n",
        "            hidden_size = list(reversed(unet.config.block_out_channels))[block_id]\n",
        "        elif name.startswith(\"down_blocks\"):\n",
        "            block_id = int(name[len(\"down_blocks.\")])\n",
        "            hidden_size = unet.config.block_out_channels[block_id]\n",
        "        if cross_attention_dim is None:\n",
        "            if name.startswith(\"up_blocks\") :\n",
        "                attn_procs[name] = SpatialAttnProcessor2_0(id_length = id_length)\n",
        "            else:\n",
        "                attn_procs[name] = AttnProcessor()\n",
        "        else:\n",
        "            attn_procs[name] = AttnProcessor()\n",
        "\n",
        "    unet.set_attn_processor(attn_procs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "# Set OpenAI API key\n",
        "openai.api_key = \"\"  # Replace with your OpenAI API key\n",
        "\n",
        "\n",
        "def suggest_visual_elements(poem):\n",
        "    \"\"\"\n",
        "    LLM suggests initial visual elements based on the entire poem.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Here is a poem:\n",
        "\"{poem}\"\n",
        "\n",
        "Suggest detailed visual elements that represent the poem's mood, imagery, and key themes. Focus on creating a description that can guide artwork creation. Return one detailed description.\n",
        "    \"\"\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=200,\n",
        "    )\n",
        "    description = response['choices'][0]['message']['content']\n",
        "    return description.strip()\n",
        "\n",
        "def critique_and_refine(poem, segment,description):\n",
        "    \"\"\"\n",
        "    LLM critiques the description for alignment with the poem and suggests refinements.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Here is a poem:\n",
        "\"{poem}\"\n",
        "\n",
        "the segment of the poem is:\n",
        "\"{segment}\" from which the desription is made\n",
        "\n",
        "Here is an initial visual description:\n",
        "\"{description}\"\n",
        "\n",
        "Review how well this description matches the poem's mood, themes, and imagery present in the segment. Update the description to better align with the segment of the poem. Return only the updated description.\n",
        "    \"\"\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=150,\n",
        "    )\n",
        "    refinement = response['choices'][0]['message']['content']\n",
        "    return refinement.strip()\n",
        "\n",
        "def feedback_loop(poem,segment,description, max_iterations=5):\n",
        "    \"\"\"\n",
        "    Iterative feedback loop to refine visual elements for the entire poem.\n",
        "    \"\"\"\n",
        "    # description = suggest_visual_elements(poem)\n",
        "    print(f\"Initial Visual Description: {description}\")\n",
        "    generated_discriptions=[]\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        print(f\"--- Iteration {iteration + 1} ---\")\n",
        "        refinement = critique_and_refine(poem, segment,description)\n",
        "        print(f\"Refined Description (Iteration {iteration + 1}): {refinement}\")\n",
        "        description = refinement  # Update description for next iteration\n",
        "        generated_discriptions.append(description)\n",
        "\n",
        "    return generated_discriptions  # Return the final refined description\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    df= pd.read_csv(\"/content/real_main_character.csv\")\n",
        "    poems = df[\"poems\"]\n",
        "    first_iteration_descriptions=[]\n",
        "    second_iteration_descriptions=[]\n",
        "    third_iteration_descriptions=[]\n",
        "    fouth_iteration_descriptions=[]\n",
        "    fifth_iteration_descriptions=[]\n",
        "    updated_descriptions =[]\n",
        "    for i,poem in enumerate(poems):\n",
        "        segments = eval(df[\"segments\"][i])\n",
        "        descriptions = eval(df[\"descriptions\"][i])\n",
        "        fir_dis=[]\n",
        "        sec_dis=[]\n",
        "        third_dis=[]\n",
        "        fouth_dis=[]\n",
        "        fifth_dis=[]\n",
        "        up_descriptions=[]\n",
        "        for j,segment in enumerate(segments):\n",
        "          description = descriptions[j]\n",
        "          final_visual_elements = feedback_loop(poem,segment,description, max_iterations=5)\n",
        "          print(\"\\nFinal Visual Elements for the Poem:\")\n",
        "          print(final_visual_elements[-1])\n",
        "          fir_dis.append(f\" ({final_visual_elements[0]})\")\n",
        "          sec_dis.append(f\"({final_visual_elements[1]})\")\n",
        "          third_dis.append(f\"({final_visual_elements[2]})\")\n",
        "          fouth_dis.append(f\"({final_visual_elements[3]})\")\n",
        "          fifth_dis.append(f\"({final_visual_elements[4]})\")\n",
        "          up_descriptions.append(final_visual_elements[-1])\n",
        "        first_iteration_descriptions.append(fir_dis)\n",
        "        second_iteration_descriptions.append(sec_dis)\n",
        "        third_iteration_descriptions.append(third_dis)\n",
        "        fouth_iteration_descriptions.append(fouth_dis)\n",
        "        fifth_iteration_descriptions.append(fifth_dis)\n",
        "        updated_descriptions.append(up_descriptions)\n",
        "    df[\"updated_descriptions\"]=updated_descriptions\n",
        "    df[\"first_iteration\"]=first_iteration_descriptions\n",
        "    df[\"second_iteration\"]=second_iteration_descriptions\n",
        "    df[\"third_iteration\"]=third_iteration_descriptions\n",
        "    df[\"fouth_iteration\"]=fouth_iteration_descriptions\n",
        "    df[\"fifth_iteration\"]=fifth_iteration_descriptions\n",
        "    df.to_csv(\"real_all_descriptions.csv\")\n",
        "#     poem = \"\"\"\n",
        "# The soote season, that bud and bloom forth brings,\n",
        "# With green hath clad the hill and eke the vale:\n",
        "# The nightingale with feathers new she sings;\n",
        "# The turtle to her make hath told her tale.\n",
        "# Summer is come, for every spray now springs:\n",
        "# The hart hath hung his old head on the pale;\n",
        "# The buck in brake his winter coat he flings;\n",
        "# The fishes flete with new repaired scale.\n",
        "# The adder all her slough away she slings;\n",
        "# The swift swallow pursueth the flies smale;\n",
        "# The busy bee her honey now she mings;\n",
        "# Winter is worn that was the flowers' bale.\n",
        "# And thus I see among these pleasant things\n",
        "# Each care decays, and yet my sorrow springs.\n",
        "#     \"\"\"\n",
        "\n",
        "#     final_visual_elements = feedback_loop(poem, max_iterations=5)\n",
        "#     print(\"\\nFinal Visual Elements for the Poem:\")\n",
        "#     print(final_visual_elements)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImlpTfIuD4C7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"/content/long_all_descriptions_modified.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rQ73JkBe4oM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.mkdir(\"long_poems\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2wZ3QO4IGS-Q",
        "outputId": "9aba8f5a-19f3-423f-f73e-4bb653fffec6"
      },
      "outputs": [],
      "source": [
        "for i in range(len(df)):\n",
        "  os.mkdir(f\"long_poems/{i}\")\n",
        "  llm_prompts = eval(df[\"first_iteration\"][i])\n",
        "  global attn_count, total_count, id_length, total_length,cur_step, cur_model_type\n",
        "  global write\n",
        "  global  sa32, sa64\n",
        "  global height,width\n",
        "  attn_count = 0\n",
        "  total_count = 0\n",
        "  cur_step = 0\n",
        "  if len(llm_prompts)>=4:\n",
        "      id_length = 4\n",
        "  else:\n",
        "    id_length = len(llm_prompts)\n",
        "  total_length = len(llm_prompts)\n",
        "  cur_model_type = \"\"\n",
        "  device=\"cuda\"\n",
        "  global attn_procs,unet\n",
        "  attn_procs = {}\n",
        "  ###\n",
        "  write = False\n",
        "  ### strength of consistent self-attention: the larger, the stronger\n",
        "  sa32 = 0.5\n",
        "  sa64 = 0.5\n",
        "  ### Res. of the Generated Comics. Please Note: SDXL models may do worse in a low-resolution!\n",
        "  height = 768\n",
        "  width = 768\n",
        "  ###\n",
        "  global pipe\n",
        "  global sd_model_path\n",
        "  sd_model_path = models_dict[\"SDXL\"] #\"SG161222/RealVisXL_V4.0\"\n",
        "  ### LOAD Stable Diffusion Pipeline\n",
        "  pipe = StableDiffusionXLPipeline.from_pretrained(sd_model_path, torch_dtype=torch.float16)\n",
        "  pipe = pipe.to(device)\n",
        "  pipe.enable_freeu(s1=0.6, s2=0.4, b1=1.1, b2=1.2)\n",
        "  pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "  pipe.scheduler.set_timesteps(50)\n",
        "  unet = pipe.unet\n",
        "\n",
        "  ### Insert PairedAttention\n",
        "  for name in unet.attn_processors.keys():\n",
        "      cross_attention_dim = None if name.endswith(\"attn1.processor\") else unet.config.cross_attention_dim\n",
        "      if name.startswith(\"mid_block\"):\n",
        "          hidden_size = unet.config.block_out_channels[-1]\n",
        "      elif name.startswith(\"up_blocks\"):\n",
        "          block_id = int(name[len(\"up_blocks.\")])\n",
        "          hidden_size = list(reversed(unet.config.block_out_channels))[block_id]\n",
        "      elif name.startswith(\"down_blocks\"):\n",
        "          block_id = int(name[len(\"down_blocks.\")])\n",
        "          hidden_size = unet.config.block_out_channels[block_id]\n",
        "      if cross_attention_dim is None and (name.startswith(\"up_blocks\") ) :\n",
        "          attn_procs[name] =  SpatialAttnProcessor2_0(id_length = id_length)\n",
        "          total_count +=1\n",
        "      else:\n",
        "          attn_procs[name] = AttnProcessor()\n",
        "  print(\"successsfully load consistent self-attention\")\n",
        "  print(f\"number of the processor : {total_count}\")\n",
        "  unet.set_attn_processor(copy.deepcopy(attn_procs))\n",
        "  global mask1024,mask4096\n",
        "  mask1024, mask4096 = cal_attn_mask_xl(total_length,id_length,sa32,sa64,height,width,device=device,dtype= torch.float16)\n",
        "  guidance_scale = 3.0\n",
        "  seed = 2047\n",
        "  sa32 = 0.5\n",
        "  sa64 = 0.5\n",
        "  num_steps = 30\n",
        "  general_prompt = df[\"main character\"][i]\n",
        "  negative_prompt =\"out of frame, lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature\"\n",
        "  prompt_array =llm_prompts\n",
        "\n",
        "  def apply_style_positive(style_name: str, positive: str):\n",
        "      p, n = styles.get(style_name, styles[DEFAULT_STYLE_NAME])\n",
        "      return p.replace(\"{prompt}\", positive)\n",
        "  def apply_style(style_name: str, positives: list, negative: str = \"\"):\n",
        "      p, n = styles.get(style_name, styles[DEFAULT_STYLE_NAME])\n",
        "      return [p.replace(\"{prompt}\", positive) for positive in positives], n + ' ' + negative\n",
        "  ### Set the generated Style\n",
        "  style_name = \"realistic\"\n",
        "  setup_seed(seed)\n",
        "  generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "  prompts = [general_prompt+\",\"+prompt for prompt in prompt_array]\n",
        "  id_prompts = prompts[:id_length]\n",
        "  real_prompts = prompts[id_length:]\n",
        "  torch.cuda.empty_cache()\n",
        "  write = True\n",
        "  cur_step = 0\n",
        "  attn_count = 0\n",
        "  id_prompts, negative_prompt = apply_style(style_name, id_prompts, negative_prompt)\n",
        "  id_images = pipe(id_prompts, num_inference_steps = num_steps, guidance_scale=guidance_scale,  height = height, width = width,negative_prompt = negative_prompt,generator = generator).images\n",
        "\n",
        "  write = False\n",
        "  for j,id_image in enumerate(id_images):\n",
        "      id_image.save(f\"long_poems/{i}/{j}.png\")\n",
        "      display(id_image)\n",
        "  real_images = []\n",
        "  for real_prompt in real_prompts:\n",
        "      cur_step = 0\n",
        "      real_prompt = apply_style_positive(style_name, real_prompt)\n",
        "      real_images.append(pipe(real_prompt,  num_inference_steps=num_steps, guidance_scale=guidance_scale,  height = height, width = width,negative_prompt = negative_prompt,generator = generator).images[0])\n",
        "  for k,real_image in enumerate(real_images):\n",
        "      real_image.save(f\"long_poems/{i}/{id_length+k}.png\")\n",
        "      display(real_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "HHDCAdutTAXU",
        "outputId": "0bae956a-54c9-4657-a2f8-b8afa1800523"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"#       print(f\\\"Shape of the embedding: {embedding\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 0.3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"poems\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\nThere\\u2019s a man who hides behind his walls,\\nChasing shadows that echo his calls.\\nThe weight of silence fills his space,\\nA world outside, he cannot face.\\n\\nThe sun still rises every day,\\nBut darkness never seems to fade away.\\nThe struggle for light\\u2014so real, so true\\u2014\\nA battle fought by more than a few.\",\n          \"\\nThey whisper in the corners, unseen, unheard,\\nThe homeless, the broken, the lost in the dirt.\\nForgotten by the world that walks by so fast,\\nCaught in a system that was never meant to last.\\n\\nBut they still have stories, they still have names,\\nLives left behind in society's games.\\nIf you listen close, you'll hear their plea\\u2014\\nDon\\u2019t forget them, don\\u2019t let them be.\",\n          \"\\nWe walk the same streets, breathe the same air,\\nBut some of us breathe in despair.\\nWhere the color of skin or the place you\\u2019re born,\\nDefines the chances for which you're sworn.\\n\\nA world built on ancient lies,\\nWhere the rich grow fat and the poor subsides.\\nThe echo rings, and none can deny,\\nThat some will fall and others fly.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"segments\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"['\\\\nThere\\u2019s a man who hides behind his walls,\\\\nChasing shadows that echo his calls.\\\\nThe weight of silence fills his space,\\\\nA world outside, he cannot face.', 'The sun still rises every day,\\\\nBut darkness never seems to fade away.\\\\nThe struggle for light\\u2014so real, so true\\u2014\\\\nA battle fought by more than a few.']\",\n          \"['\\\\nThey whisper in the corners, unseen, unheard,\\\\nThe homeless, the broken, the lost in the dirt.\\\\nForgotten by the world that walks by so fast,\\\\nCaught in a system that was never meant to last.', \\\"But they still have stories, they still have names,\\\\nLives left behind in society's games.\\\\nIf you listen close, you'll hear their plea\\u2014\\\\nDon\\u2019t forget them, don\\u2019t let them be.\\\"]\",\n          \"[\\\"\\\\nWe walk the same streets, breathe the same air,\\\\nBut some of us breathe in despair.\\\\nWhere the color of skin or the place you\\u2019re born,\\\\nDefines the chances for which you're sworn.\\\", 'A world built on ancient lies,\\\\nWhere the rich grow fat and the poor subsides.\\\\nThe echo rings, and none can deny,\\\\nThat some will fall and others fly.']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"main character\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Lonely man\",\n          \"Forgotten souls\",\n          \"Societal observer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"descriptions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[\\\"Visualize a solitary figure standing in a dimly lit room, surrounded by towering, crumbling walls that symbolize emotional barriers. Shadows dance eerily on the wall, mirroring the man's lingering doubts and fears. His expression is one of longing, revealing a deep yearning for connection yet paralyzed by the suffocating silence. Outside the window, a bright, bustling world thrives, filled with vibrant colors and sounds, a stark contrast to his shadowy confines. Capture the essence of isolation and the struggle against the overwhelming weight of silence, portraying an inner battle between safety and the desire for freedom.\\\", 'Picture the same solitary figure, now standing at the window, gazing out at the perpetually rising sun that casts a warm glow outside. Yet, deep shadows cling to his form, symbolizing the darkness that stubbornly lingers within. The rays of light seem to reach for him, offering hope, yet he remains trapped by emotional turmoil. This stark contrast between the vibrant world outside and his internal confinement vividly illustrates the struggle for illumination in his life. Visualize the ongoing battle between the promise of dawn and the suffocating embrace of night, emphasizing the resilience of the human spirit in the face of adversity.']\",\n          \"['Visualize a dimly lit urban alleyway where shadows loom, reflecting the lives of the homeless. Frayed blankets and tattered belongings signify the broken spirits of those who dwell there. Murmurs of sorrow fill the air, their presence felt yet invisible to the hurried pedestrians above. The walls are adorned with graffiti, bold yet poignant, encapsulating the struggle against a fleeting world. A flickering streetlamp casts an eerie glow, illuminating the stark reality of abandonment. Amidst discarded waste, a flicker of human connection emerges, reminding us of the resilience hidden behind the silence of the unacknowledged.', 'In the dusky urban alley, shadows deepen as nightfall approaches. Frayed blankets lay coiled like forgotten histories, while tattered belongings tell tales of lives once vibrant. The faint echoes of muffled voices reveal a desperation, a whisper amidst the chaos of city life. Graffiti stretches across the grimy walls, each spray-painted word a testament to personal battles fought in silence. As the flickering streetlamp struggles to hold back the darkness, its light dances on faces marked by hardship, inviting a closer look. Listen intently, and you\\u2019ll discern the poignant stories beneath the surface, a collective cry to be seen and remembered.']\",\n          \"['Visualize a bustling city street, filled with diverse people walking side by side, their expressions a mix of joy and sorrow. In the foreground, a young woman gazes thoughtfully at a mural that mirrors her struggle, showcasing vibrant colors contrasted against gray backgrounds symbolizing despair. Nearby, a child clutches a worn-out toy, embodying innocence amidst hardship. The skyline looms above, radiant yet shadowed, representing the societal barriers shaped by skin color and birthplace. Sunlight breaks through the clouds, hinting at hope, merging with the air heavy with unspoken stories of resilience and longing for equality.', \\\"Imagine a stark contrast between wealth and poverty on a city street, where the affluent stride confidently past crumbling facades. In the foreground, a group of prosperous individuals laugh, their laughter piercing the air, oblivious to the hardship surrounding them. A homeless man, shadowed in the backdrop, sits against a wall draped in faded advertisements, embodying the bitter truth of society's divide. Above them, skyscrapers gleam with sunlight, casting long shadows over those below, symbolizing the unyielding barriers of class and privilege. In the distance, a flicker of hope appears\\u2014a community rallying together, united in their struggle against the ancient lies that bind them.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"updated_descriptions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[\\\"Visualize a solitary man ensconced within a dim, enclosed space, surrounded by towering, crumbling walls that represent his self-imposed isolation. He stands in oppressive silence, where shadows flit and flicker, echoing the calls he dare not voice. The weight of solitude rests heavily upon him, etched in the lines of his face, revealing unspoken fears and a deep yearning for connection. Outside, faint hints of a vibrant world hint at the light and life he cannot face, amplifying his profound disconnection. This image embodies the essence of entrapment and the silent struggle against loneliness, perfectly reflecting the poem's poignant exploration of isolation and the complex emotions that accompany the desire for a brighter existence.\\\", '\\\"Picture a solitary figure standing by the window, gazing at the sun as it rises, casting hopeful golden rays into the world. Yet, despite this daily ritual of renewal, shadows cling to him, a persistent darkness that seems to swallow the light whole. The struggle for illumination is palpable; the sunlight represents not just hope, but a yearning for liberation from the weight of despair that shadows his spirit. This stark juxtaposition between the vivid dawn and his enduring gloom powerfully illustrates the universal battle for clarity and joy\\u2014a struggle faced by many. It highlights the resilience required to confront life\\\\'s ongoing challenges, reminding us that the pursuit of light is a shared journey, resonating deeply in the hearts of countless others.\\\"']\",\n          \"['\\\"Visualize a dimly lit urban alleyway, where shadows gather in the corners, representing the unseen and unheard. Tattered blankets lie on the cold, hard ground, emblematic of the homeless, the broken, and those lost amidst the dirt\\u2014echoes of lives neglected in a world that rushes by. The hurried footsteps of pedestrians resonate above, indifferent to the silent struggles of those trapped in a system designed to overlook them. The walls are adorned with graffiti, stark images of despair and resilience, reflecting the spirits of individuals left behind. A flickering streetlamp casts a weak light, struggling to illuminate the stark reality of abandonment and neglect, as an oppressive silence hangs heavy in the air, urging us not to forget those who suffer in', \\\"In the shadows of the urban alley, the remnants of forgotten lives whisper softly, each frayed blanket and scattered possession holding a story of resilience. Amidst the harsh realities and relentless pace of society's games, these items bear witness to the names and identities that haunt the corners, yearning to be acknowledged. The air is thick with the weight of unvoiced pleas, echoes of struggles rising above the city's clamor, inviting us to listen closely. Vibrant graffiti sprawls across the walls, a testament to individuality and a poignant call for recognition, reminding us that these souls are more than their circumstances. Each mark and message implores us to remember, urging us to see the humanity behind the facelessness and not to let their stories fade into\\\"]\",\n          \"['Visualize a bustling city street where the air is thick with contrasting emotions\\u2014some faces shine with a resilient hope while others are clouded by despair. In the foreground, a young woman stands with a furrowed brow, her eyes reflecting the heavy toll of systemic inequalities that bind individuals to their destinies. Each passerby tells a story shaped by the invisible barriers of race and birthplace, their expressions revealing the stark divide between aspiration and defeat. Nearby, a mural depicts vibrant colors clashing with muted tones, symbolizing the struggle against the constraints imposed by identity. A child, holding a worn-out toy, stands at the edge of the crowd, their gaze revealing a mixture of innocence and awareness, caught in the web of circumstance. The skyline lo', 'Envision a cityscape steeped in stark contrasts, where the echoes of social injustice reverberate through the air. In the foreground, a group of affluent individuals, laughing and indulging in their wealth, remain blissfully unaware of the burdens borne by those around them. Their carefree joy stands in sharp relief against a weary figure of a homeless man, slumped against a crumbling wall, surrounded by discarded remnants of a society driven by consumption\\u2014tattered signs of lost dreams and aspirations. Towering skyscrapers rise like monuments to excess, their gleaming surfaces reflecting a harsh, unforgiving sun, while deep shadows spiral from their heights, casting darkness over the struggles of the marginalized below. This scene powerfully embodies a world built on ancient lies']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"first_iteration\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[' (\\\"Envision a solitary figure ensconced in a dim, confined space, characterized by towering, crumbling walls that embody his emotional barriers. He stands amidst a heavy silence, shadows creeping along the walls, echoing his calls and reflecting his inner turmoil. The man\\u2019s expression is a mix of longing and trepidation, revealing a profound yearning for connection yet frozen by the oppressive stillness that surrounds him. Outside the partially obscured window, a vibrant world thrives, alive with light and activity, starkly contrasting the darkness of his enclosure. This image captures the essence of isolation and the silent struggle against the weight of solitude, mirroring the poem\\\\'s themes of emotional entrapment and the yearning for a distant, brighter reality.\\\")', ' (\\\"Imagine a solitary figure standing at the window, looking out as the sun climbs steadily into the sky, its warm glow offering a promise of a new day. Yet, despite the bright rays streaming outside, shadows linger heavily around him, embodying the darkness that refuses to dissipate. The sunlight reaches toward him, symbolizing hope and the struggle for light, yet he remains ensnared by the weight of his emotional turmoil. This stark contrast between the vibrant dawn and the persistent shadows captures the essence of his battle\\u2014a fight for clarity and peace that resonates beyond his solitary existence. The scene evokes an understanding that this internal struggle is shared by many, emphasizing the resilience required to confront the challenges that come with the quest for illumination.\\\")']\",\n          \"[' (\\\"Visualize a dimly lit urban alleyway, where shadows cling to the walls, echoing the lives of the homeless and the broken. Tattered blankets and scattered belongings lie as testaments to their struggles, whispered stories mingling with the sorrowful silence that fills the air. Unseen by the world that rushes by, their presence lingers in the cracks of society, a reflection of lives forgotten. The walls, marked with bold graffiti, speak of a fight against a system that overlooks their plight. A flickering streetlamp casts an uneven glow, revealing a stark reality of neglect while hinting at flickers of resilience among the remnants of discarded hope. This space, heavy with the weight of unacknowledged existence, serves as)', \\\" (In the shadowy recesses of the urban alley, the air thickens with untold stories as night descends. Frayed blankets lie abandoned, echoing lives that once pulsed with hope, now caught in the grip of neglect. Tattered belongings are scattered like fragments of forgotten dreams, each one a silent testament to the struggles endured. The hushed murmurs reveal a poignant plea, a desperate longing to be heard amidst the city's relentless noise. Graffiti, vibrant yet sorrowful, covers the walls\\u2014a chorus of individual battles, each spray-painted word a call to remember. As the flickering streetlamp battles encroaching darkness, its struggling light illuminates faces etched with hardship, urging passersby to pause and listen. In this)\\\"]\",\n          \"[' (\\\"Visualize a bustling city street, where the vibrant energy of diverse individuals coexists with a palpable tension. In the foreground, a young woman stands contemplatively, her gaze fixed on a mural that depicts the struggle against systemic injustice; the artwork bursts with colors yet carries shadows that mirror the despair she feels. Nearby, a child clutches a faded toy, a symbol of innocence overshadowed by circumstance. The towering skyline looms above, bright on one side but cast in shadows, representing the societal divides dictated by skin color and birthplace. Strands of sunlight filter through heavy clouds, illuminating the faces of those who refuse to be defined by their circumstances, hinting at the resilience and hope for a more equitable future.\\\")', ' (\\\"Envision a cityscape dominated by stark divisions, where shadows of wealth loom over the disadvantaged. In the foreground, a tight-knit group of affluent individuals stands, their laughter echoing with an air of insensitivity, oblivious to the struggles unfolding a mere few steps away. Behind them, a solitary homeless man huddles against a dilapidated wall, surrounded by discarded remnants of consumerism\\u2014faded advertisements that whisper tales of dreams long deferred. Towering skyscrapers rise in the background, glistening under the sun yet casting heavy shadows that envelop those who are left behind. The scene captures the palpable tension of a society structured on ancient lies, revealing the cruel reality of a world where the privileged soar while the marginalized linger in silence)']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"second_iteration\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[\\\"(Envision a solitary figure hidden within a dim, confining space, surrounded by towering, crumbling walls that symbolize his emotional barriers. He stands in the oppressive silence, where shadows dance along the walls, echoing his calls and mirroring his inner turmoil. The man\\u2019s face reflects a complex mix of longing and fear, conveying his deep yearning for connection while being paralyzed by the heavy stillness that envelops him. Outside the partially obscured window lies a vibrant world, alive with light and sound, but remains beyond his reach, emphasizing his sense of disconnection. This image embodies the essence of isolation and the silent struggle against the weight of loneliness, resonating powerfully with the poem's themes of emotional entrapment and the haunting desire)\\\", '(Imagine a solitary figure standing at the window, gazing out as the sun ascends steadily into the sky, its golden rays promising the dawn of a new day. Yet, despite the warmth enveloping the world outside, an impenetrable darkness clings to him, symbolizing the shadows that linger within. The sunlight reaches out, embodying hope and the struggle for light, yet he remains weighed down by the heaviness of his emotional plight. This poignant contrast between the vibrant morning and the suffocating shadows captures the essence of his internal battle\\u2014a relentless fight for clarity and peace that resonates deeply with many. The scene powerfully reflects the shared resilience required to confront the ongoing challenges that accompany the quest for illumination, underscoring the truth that)']\",\n          \"['(Visualize a dimly lit urban alleyway, where shadows cling to the walls, echoing the presence of the homeless and the broken. Tattered blankets and scattered belongings speak of lives left behind, their stories lingering in the air like silent whispers. The world rushes by, oblivious to the struggles etched in the dirt, trapped in a system designed to forget them. Graffiti on the walls embodies both frustration and resilience, a testament to the fight against an indifferent society. A flickering streetlamp casts an uneven light, revealing the stark reality of neglect while hinting at the persistent spirit of those who remain unseen. This space, heavy with unacknowledged existence, captures the essence of lives marginalized, evoking a call to remember the)', \\\"(In the shadowy recesses of the urban alley, the air thickens with untold stories and the weight of forgotten names. Frayed blankets lie abandoned, a reminder of lives once vibrant, now overshadowed by neglect. Scattered belongings whisper of dreams left behind, each item a silent testament to the struggles that continue to echo in the night. If you listen closely, you can hear the hushed pleas of those who yearn to be seen, their voices rising above the city's relentless noise. Graffiti\\u2014vibrant yet sorrowful\\u2014adorns the walls, each spray-painted word a poignant call to action, a reminder that these individuals are more than just their circumstances. As the flickering streetlamp struggles to illuminate the darkness, it)\\\"]\",\n          \"['(Visualize a bustling city street, alive with the diverse rhythms of its inhabitants, yet underscored by an air of tension and despair. In the foreground, a young woman stands with a furrowed brow, her eyes scanning the mosaic of faces that surround her, each reflecting a spectrum of experiences bound by the invisible chains of systemic injustice. A mural nearby illustrates the stark realities faced by many, vibrant colors intertwining with dark shades that represent the weight of societal expectations based on skin color and birthplace. A child nearby clutches a worn toy, embodying innocence that is marred by the cruel hand of fate. The looming skyline casts an uneven light, with certain areas basking in brightness while others are shrouded in shadow, a poignant)', '(Envision a cityscape steeped in stark contrasts, where opulence looms over despair. In the foreground, a group of wealthy individuals, wrapped in laughter, stand oblivious to the silent suffering that surrounds them. Their joy is a sharp contrast to the forlorn figure of a homeless man huddled against a crumbling wall, surrounded by discarded symbols of a consumer-driven society\\u2014tattered posters and defunct products that tell stories of lost aspirations. Towering skyscrapers stretch towards the sky, gleaming under a harsh sun, yet casting deep shadows that engulf those left behind. The scene encapsulates the unsettling reality of a world built on ancient lies, where privilege thrives audaciously while the marginalized struggle to survive, caught in a cycle)']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"third_iteration\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[\\\"(Envision a solitary figure ensconced within a dim, confining space, surrounded by towering, crumbling walls that embody his emotional barriers. He stands enveloped in oppressive silence, where shadows flicker across the walls, echoing his calls and mirroring his internal struggle. The man's face bears the weight of unspoken fears and a profound longing for connection, trapped within the stillness that surrounds him. Outside the faintly visible window lies a world brimming with life and light, yet forever out of reach, underscoring his profound sense of disconnection. This image captures the essence of isolation and the silent battle against the suffocating weight of loneliness, resonating deeply with the poem's themes of entrapment and the haunting search)\\\", '(\\\"Imagine a solitary figure standing at the window, watching as the sun breaks over the horizon, its golden rays stretching to greet the day. Yet, despite the promise of warmth and renewal in the world outside, an inescapable darkness clings to him, mirroring the shadows of doubt and despair that persist within. The sunlight represents hope and the longing for clarity, but he feels the weight of his emotional struggle, trapped in a cycle where the light never quite penetrates his internal gloom. This striking contrast between the vibrant morning and his engulfing shadows encapsulates his relentless fight for light\\u2014a struggle that resonates with many. The scene poignantly illustrates the shared resilience required to face ongoing challenges, emphasizing the truth that the quest for illumination is a)']\",\n          \"['(Visualize a dimly lit urban alleyway, where shadows linger in the corners, embodying the presence of the unseen and unheard. Tattered blankets and discarded belongings scatter across the ground, each item a fragment of lives overlooked, whispering untold stories that fade into the chaos of a rushing world. The hurried footsteps of passersby echo, oblivious to the lost souls caught in a relentless system, one that was never meant to embrace them. Graffiti on the walls serves as a haunting reminder of the struggles and resilience intertwined in their existence, expressing both despair and an indomitable spirit. A flickering streetlamp casts an uneven glow, illuminating the stark reality of abandonment while calling out for acknowledgment. This space, heavy with the weight)', \\\"(In the depths of the urban alley, where shadows linger and whispers fade, the remnants of lives once vibrant now lay forgotten. Frayed blankets and scattered belongings tell stories yearning to be heard\\u2014each item a silent echo of dreams abandoned and struggles that persist. The air is thick with the weight of unspoken names, a haunting reminder of those left behind in society's relentless games. As you pause to listen, the hushed pleas of the unseen rise above the city's din, longing for acknowledgment and connection. Graffiti, both vivid and sorrowful, adorns the walls\\u2014a poignant reminder that these individuals are more than their circumstances, each spray-painted word a call to remember their existence. Bathed in the flickering light of a weary streetlamp,)\\\"]\",\n          \"[\\\"(Visualize a bustling city street, where the air is thick with contrasting emotions\\u2014some faces beam with optimism while others harbor deep-seated despair. In the foreground, a young woman stands with a furrowed brow, her eyes reflecting the weight of systemic inequities as she observes the array of individuals around her. Each face tells a story shaped by the invisible barriers of race and birthplace, evident in the expressions of hope and defeat. A nearby mural vividly depicts these struggles, bright colors clashing with darker tones to symbolize the duality of aspiration and limitation based on one's identity. A child nearby grips a tattered toy, embodying the blamelessness of youth, yet caught in the web of circumstance. The city skyline looms overhead,)\\\", '(\\\"Envision a cityscape steeped in stark contrasts, where wealth and privilege create an imposing fa\\u00e7ade over a backdrop of pervasive despair. In the foreground, a group of affluent individuals, immersed in laughter and luxury, remain oblivious to the silent suffering of those around them. Their carefree joy sharply juxtaposes the weary figure of a homeless man, hunched against a crumbling wall, encapsulated by discarded remnants of a consumer-driven society\\u2014tattered signs of aspiration lost in the shadows. Towering skyscrapers loom overhead, their gleaming surfaces reflecting a harsh sun, while dark shadows spiral from their heights, engulfing those marginalized beneath. This scene strikingly captures a world built on ancient lies, where the echoes of social injustice resound, and)']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fouth_iteration\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"['(\\\"Visualize a solitary man ensconced within a dim, confined space, enveloped by towering, crumbling walls that symbolize his self-imposed isolation. He stands in oppressive silence, as shadows dance across the walls, echoing his unfulfilled calls and reflecting his inner turmoil. The weight of solitude is palpable in his expression, revealing unspoken fears and a yearning for connection. Outside, a faintly visible world teems with light and life, but remains forever out of his reach, amplifying his sense of disconnection. This image captures the essence of entrapment and the silent struggle against the burdens of loneliness, mirroring the poem\\\\'s poignant themes of isolation and the longing for a brighter existence.\\\")', '(Imagine a solitary figure standing at the window, watching the sun rise with golden rays that stretch into the day. Despite this daily promise of warmth and renewal, an unyielding darkness envelops him, mirroring the shadows of doubt and despair that linger within. The sunlight symbolizes hope and the yearning for clarity, yet he feels trapped in an internal struggle where light never fully dispels the gloom. This poignant contrast between the vibrant morning and his persistent shadows beautifully captures the profound battle for illumination\\u2014a struggle that is all too familiar for many. It emphasizes the shared resilience needed to confront ongoing challenges, underscoring the truth that the quest for light is not just personal, but a collective experience echoed in the lives of many.)']\",\n          \"['(Visualize a dimly lit urban alleyway, where shadows collect in the corners, symbolizing the unseen and unheard. Tattered blankets drape over cold, hard ground, whispering the stories of the homeless, the broken, and the lost\\u2014echoes of lives overlooked in the swift current of a world that passes them by. The hurried footsteps of pedestrians resonate through the air, indifferent to the struggles of those caught in a relentless system that fails them. Graffiti on the walls speaks volumes of despair and resilience, capturing the essence of unyielding spirits amidst abandonment. A flickering streetlamp struggles to cast light on the stark reality, illuminating the forgotten and pleading for acknowledgment, as the weight of neglect hangs heavy in the atmosphere.)', \\\"(In the depths of the urban alley, where shadows linger and whispers fade, the remnants of lives once vibrant now lay forgotten. Frayed blankets and scattered belongings tell silent stories, each item a testament to the names and lives left behind in society's relentless games. The air is thick with unspoken pleas, a haunting reminder of those yearning to be seen and remembered. As you pause to listen, the echoes of their struggles rise above the city's din, longing for connection and acknowledgment. Graffiti adorns the walls\\u2014both vivid and sorrowful\\u2014serving as poignant reminders that these individuals are more than their circumstances. Each spray-painted word calls for recognition of their existence, urging us to remember and not let them fade away. Bathed in the flick)\\\"]\",\n          \"['(Visualize a bustling city street where the air is thick with contrasting emotions\\u2014some faces shine with optimism while others are etched with despair. In the foreground, a young woman stands with a furrowed brow, her eyes reflecting the weight of systemic inequalities that tie individuals to their fates. Each passerby embodies a narrative shaped by the invisible barriers of race and birthplace, their expressions revealing the stark divide between hope and defeat. Nearby, a mural comes to life with vivid colors clashing against somber hues, symbolizing the struggle between aspiration and limitation based on identity. A child holds a worn-out toy, innocently caught in the web of circumstance, their gaze filled with curiosity yet hinting at the weight of the world around them. The skyline)', '(Envision a cityscape steeped in stark contrasts, where the echoes of social injustice reverberate through the air. In the foreground, a group of affluent individuals, laughing and indulging in their wealth, remain blissfully unaware of the silent suffering surrounding them. Their carefree joy stands in sharp relief against a weary figure of a homeless man, hunched against a crumbling wall, enveloped by discarded remnants of a society driven by consumption\\u2014tattered signs of lost dreams and aspirations. Towering skyscrapers rise like monuments to excess, their gleaming surfaces reflecting a harsh, unforgiving sun, while deep shadows spiral from their heights, casting darkness over those who struggle beneath. This scene powerfully embodies a world built on ancient lies, where the)']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fifth_iteration\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[\\\"(Visualize a solitary man ensconced within a dim, enclosed space, surrounded by towering, crumbling walls that represent his self-imposed isolation. He stands in oppressive silence, where shadows flit and flicker, echoing the calls he dare not voice. The weight of solitude rests heavily upon him, etched in the lines of his face, revealing unspoken fears and a deep yearning for connection. Outside, faint hints of a vibrant world hint at the light and life he cannot face, amplifying his profound disconnection. This image embodies the essence of entrapment and the silent struggle against loneliness, perfectly reflecting the poem's poignant exploration of isolation and the complex emotions that accompany the desire for a brighter existence.)\\\", '(\\\"Picture a solitary figure standing by the window, gazing at the sun as it rises, casting hopeful golden rays into the world. Yet, despite this daily ritual of renewal, shadows cling to him, a persistent darkness that seems to swallow the light whole. The struggle for illumination is palpable; the sunlight represents not just hope, but a yearning for liberation from the weight of despair that shadows his spirit. This stark juxtaposition between the vivid dawn and his enduring gloom powerfully illustrates the universal battle for clarity and joy\\u2014a struggle faced by many. It highlights the resilience required to confront life\\\\'s ongoing challenges, reminding us that the pursuit of light is a shared journey, resonating deeply in the hearts of countless others.\\\")']\",\n          \"['(\\\"Visualize a dimly lit urban alleyway, where shadows gather in the corners, representing the unseen and unheard. Tattered blankets lie on the cold, hard ground, emblematic of the homeless, the broken, and those lost amidst the dirt\\u2014echoes of lives neglected in a world that rushes by. The hurried footsteps of pedestrians resonate above, indifferent to the silent struggles of those trapped in a system designed to overlook them. The walls are adorned with graffiti, stark images of despair and resilience, reflecting the spirits of individuals left behind. A flickering streetlamp casts a weak light, struggling to illuminate the stark reality of abandonment and neglect, as an oppressive silence hangs heavy in the air, urging us not to forget those who suffer in)', \\\"(In the shadows of the urban alley, the remnants of forgotten lives whisper softly, each frayed blanket and scattered possession holding a story of resilience. Amidst the harsh realities and relentless pace of society's games, these items bear witness to the names and identities that haunt the corners, yearning to be acknowledged. The air is thick with the weight of unvoiced pleas, echoes of struggles rising above the city's clamor, inviting us to listen closely. Vibrant graffiti sprawls across the walls, a testament to individuality and a poignant call for recognition, reminding us that these souls are more than their circumstances. Each mark and message implores us to remember, urging us to see the humanity behind the facelessness and not to let their stories fade into)\\\"]\",\n          \"['(Visualize a bustling city street where the air is thick with contrasting emotions\\u2014some faces shine with a resilient hope while others are clouded by despair. In the foreground, a young woman stands with a furrowed brow, her eyes reflecting the heavy toll of systemic inequalities that bind individuals to their destinies. Each passerby tells a story shaped by the invisible barriers of race and birthplace, their expressions revealing the stark divide between aspiration and defeat. Nearby, a mural depicts vibrant colors clashing with muted tones, symbolizing the struggle against the constraints imposed by identity. A child, holding a worn-out toy, stands at the edge of the crowd, their gaze revealing a mixture of innocence and awareness, caught in the web of circumstance. The skyline lo)', '(Envision a cityscape steeped in stark contrasts, where the echoes of social injustice reverberate through the air. In the foreground, a group of affluent individuals, laughing and indulging in their wealth, remain blissfully unaware of the burdens borne by those around them. Their carefree joy stands in sharp relief against a weary figure of a homeless man, slumped against a crumbling wall, surrounded by discarded remnants of a society driven by consumption\\u2014tattered signs of lost dreams and aspirations. Towering skyscrapers rise like monuments to excess, their gleaming surfaces reflecting a harsh, unforgiving sun, while deep shadows spiral from their heights, casting darkness over the struggles of the marginalized below. This scene powerfully embodies a world built on ancient lies)']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"['Isolation', 'Despair']\",\n          \"['Despair', 'Remembering']\",\n          \"['Despair', 'Inequality']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"interlm_emotions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"['Contemplative.', 'Lonely']\",\n          \"['Lonely', 'Hiding']\",\n          \"['Serene', 'Joyful']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intern_main\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"['Solitude', 'Solitude']\",\n          \"['Solemn', 'Blanket']\",\n          \"['Portrait', 'Friends']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-fe7b8279-33b2-4bef-84c5-0e4561ef3c01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.3</th>\n",
              "      <th>poems</th>\n",
              "      <th>segments</th>\n",
              "      <th>main character</th>\n",
              "      <th>descriptions</th>\n",
              "      <th>updated_descriptions</th>\n",
              "      <th>first_iteration</th>\n",
              "      <th>second_iteration</th>\n",
              "      <th>third_iteration</th>\n",
              "      <th>fouth_iteration</th>\n",
              "      <th>fifth_iteration</th>\n",
              "      <th>emotions</th>\n",
              "      <th>interlm_emotions</th>\n",
              "      <th>intern_main</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The rivers are dry, the oceans rise,\\nA chokin...</td>\n",
              "      <td>['The rivers are dry, the oceans rise,\\nA chok...</td>\n",
              "      <td>Nature's voice</td>\n",
              "      <td>[\"Create an evocative visual scene that captur...</td>\n",
              "      <td>['Envision a haunting landscape where dry rive...</td>\n",
              "      <td>[' (\"Create a haunting visual scene that encap...</td>\n",
              "      <td>['(\"Create an evocative visual scene that embo...</td>\n",
              "      <td>['(\"Create a haunting visual scene that captur...</td>\n",
              "      <td>[\"(Create a haunting visual scene that capture...</td>\n",
              "      <td>['(Envision a haunting landscape where dry riv...</td>\n",
              "      <td>['Despair', 'Loss']</td>\n",
              "      <td>['Serenity', 'Desolate.']</td>\n",
              "      <td>['Sand', 'Abandonment']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>\\nThere’s a man who hides behind his walls,\\nC...</td>\n",
              "      <td>['\\nThere’s a man who hides behind his walls,\\...</td>\n",
              "      <td>Lonely man</td>\n",
              "      <td>[\"Visualize a solitary figure standing in a di...</td>\n",
              "      <td>[\"Visualize a solitary man ensconced within a ...</td>\n",
              "      <td>[' (\"Envision a solitary figure ensconced in a...</td>\n",
              "      <td>[\"(Envision a solitary figure hidden within a ...</td>\n",
              "      <td>[\"(Envision a solitary figure ensconced within...</td>\n",
              "      <td>['(\"Visualize a solitary man ensconced within ...</td>\n",
              "      <td>[\"(Visualize a solitary man ensconced within a...</td>\n",
              "      <td>['Isolation', 'Despair']</td>\n",
              "      <td>['Contemplative.', 'Lonely']</td>\n",
              "      <td>['Solitude', 'Solitude']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>\\nWe walk the same streets, breathe the same a...</td>\n",
              "      <td>[\"\\nWe walk the same streets, breathe the same...</td>\n",
              "      <td>Societal observer</td>\n",
              "      <td>['Visualize a bustling city street, filled wit...</td>\n",
              "      <td>['Visualize a bustling city street where the a...</td>\n",
              "      <td>[' (\"Visualize a bustling city street, where t...</td>\n",
              "      <td>['(Visualize a bustling city street, alive wit...</td>\n",
              "      <td>[\"(Visualize a bustling city street, where the...</td>\n",
              "      <td>['(Visualize a bustling city street where the ...</td>\n",
              "      <td>['(Visualize a bustling city street where the ...</td>\n",
              "      <td>['Despair', 'Inequality']</td>\n",
              "      <td>['Serene', 'Joyful']</td>\n",
              "      <td>['Portrait', 'Friends']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>\\nA child stares at an empty plate,\\nDreaming ...</td>\n",
              "      <td>['\\nA child stares at an empty plate,\\nDreamin...</td>\n",
              "      <td>Hungry child</td>\n",
              "      <td>[\"Visualize a poignant scene: a small child wi...</td>\n",
              "      <td>['\"Visualize a poignant scene: a small child w...</td>\n",
              "      <td>[' (\"Visualize a poignant scene: a small child...</td>\n",
              "      <td>[\"(Visualize a poignant scene: a small child w...</td>\n",
              "      <td>[\"(Visualize a poignant scene: a small child w...</td>\n",
              "      <td>[\"(Visualize a poignant scene: a small child w...</td>\n",
              "      <td>['(\"Visualize a poignant scene: a small child ...</td>\n",
              "      <td>['Hunger', 'Sorrow']</td>\n",
              "      <td>['Disappointed', 'Contemplative']</td>\n",
              "      <td>['Child', 'Child']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>\\nThey whisper in the corners, unseen, unheard...</td>\n",
              "      <td>['\\nThey whisper in the corners, unseen, unhea...</td>\n",
              "      <td>Forgotten souls</td>\n",
              "      <td>['Visualize a dimly lit urban alleyway where s...</td>\n",
              "      <td>['\"Visualize a dimly lit urban alleyway, where...</td>\n",
              "      <td>[' (\"Visualize a dimly lit urban alleyway, whe...</td>\n",
              "      <td>['(Visualize a dimly lit urban alleyway, where...</td>\n",
              "      <td>['(Visualize a dimly lit urban alleyway, where...</td>\n",
              "      <td>['(Visualize a dimly lit urban alleyway, where...</td>\n",
              "      <td>['(\"Visualize a dimly lit urban alleyway, wher...</td>\n",
              "      <td>['Despair', 'Remembering']</td>\n",
              "      <td>['Lonely', 'Hiding']</td>\n",
              "      <td>['Solemn', 'Blanket']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe7b8279-33b2-4bef-84c5-0e4561ef3c01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe7b8279-33b2-4bef-84c5-0e4561ef3c01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe7b8279-33b2-4bef-84c5-0e4561ef3c01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6278d7db-3049-4621-a0da-cd4b379d9f1a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6278d7db-3049-4621-a0da-cd4b379d9f1a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6278d7db-3049-4621-a0da-cd4b379d9f1a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.3  \\\n",
              "0           0             0   \n",
              "1           1             1   \n",
              "2           2             2   \n",
              "3           3             3   \n",
              "4           4             4   \n",
              "\n",
              "                                               poems  \\\n",
              "0  The rivers are dry, the oceans rise,\\nA chokin...   \n",
              "1  \\nThere’s a man who hides behind his walls,\\nC...   \n",
              "2  \\nWe walk the same streets, breathe the same a...   \n",
              "3  \\nA child stares at an empty plate,\\nDreaming ...   \n",
              "4  \\nThey whisper in the corners, unseen, unheard...   \n",
              "\n",
              "                                            segments     main character  \\\n",
              "0  ['The rivers are dry, the oceans rise,\\nA chok...     Nature's voice   \n",
              "1  ['\\nThere’s a man who hides behind his walls,\\...         Lonely man   \n",
              "2  [\"\\nWe walk the same streets, breathe the same...  Societal observer   \n",
              "3  ['\\nA child stares at an empty plate,\\nDreamin...       Hungry child   \n",
              "4  ['\\nThey whisper in the corners, unseen, unhea...    Forgotten souls   \n",
              "\n",
              "                                        descriptions  \\\n",
              "0  [\"Create an evocative visual scene that captur...   \n",
              "1  [\"Visualize a solitary figure standing in a di...   \n",
              "2  ['Visualize a bustling city street, filled wit...   \n",
              "3  [\"Visualize a poignant scene: a small child wi...   \n",
              "4  ['Visualize a dimly lit urban alleyway where s...   \n",
              "\n",
              "                                updated_descriptions  \\\n",
              "0  ['Envision a haunting landscape where dry rive...   \n",
              "1  [\"Visualize a solitary man ensconced within a ...   \n",
              "2  ['Visualize a bustling city street where the a...   \n",
              "3  ['\"Visualize a poignant scene: a small child w...   \n",
              "4  ['\"Visualize a dimly lit urban alleyway, where...   \n",
              "\n",
              "                                     first_iteration  \\\n",
              "0  [' (\"Create a haunting visual scene that encap...   \n",
              "1  [' (\"Envision a solitary figure ensconced in a...   \n",
              "2  [' (\"Visualize a bustling city street, where t...   \n",
              "3  [' (\"Visualize a poignant scene: a small child...   \n",
              "4  [' (\"Visualize a dimly lit urban alleyway, whe...   \n",
              "\n",
              "                                    second_iteration  \\\n",
              "0  ['(\"Create an evocative visual scene that embo...   \n",
              "1  [\"(Envision a solitary figure hidden within a ...   \n",
              "2  ['(Visualize a bustling city street, alive wit...   \n",
              "3  [\"(Visualize a poignant scene: a small child w...   \n",
              "4  ['(Visualize a dimly lit urban alleyway, where...   \n",
              "\n",
              "                                     third_iteration  \\\n",
              "0  ['(\"Create a haunting visual scene that captur...   \n",
              "1  [\"(Envision a solitary figure ensconced within...   \n",
              "2  [\"(Visualize a bustling city street, where the...   \n",
              "3  [\"(Visualize a poignant scene: a small child w...   \n",
              "4  ['(Visualize a dimly lit urban alleyway, where...   \n",
              "\n",
              "                                     fouth_iteration  \\\n",
              "0  [\"(Create a haunting visual scene that capture...   \n",
              "1  ['(\"Visualize a solitary man ensconced within ...   \n",
              "2  ['(Visualize a bustling city street where the ...   \n",
              "3  [\"(Visualize a poignant scene: a small child w...   \n",
              "4  ['(Visualize a dimly lit urban alleyway, where...   \n",
              "\n",
              "                                     fifth_iteration  \\\n",
              "0  ['(Envision a haunting landscape where dry riv...   \n",
              "1  [\"(Visualize a solitary man ensconced within a...   \n",
              "2  ['(Visualize a bustling city street where the ...   \n",
              "3  ['(\"Visualize a poignant scene: a small child ...   \n",
              "4  ['(\"Visualize a dimly lit urban alleyway, wher...   \n",
              "\n",
              "                     emotions                   interlm_emotions  \\\n",
              "0         ['Despair', 'Loss']          ['Serenity', 'Desolate.']   \n",
              "1    ['Isolation', 'Despair']       ['Contemplative.', 'Lonely']   \n",
              "2   ['Despair', 'Inequality']               ['Serene', 'Joyful']   \n",
              "3        ['Hunger', 'Sorrow']  ['Disappointed', 'Contemplative']   \n",
              "4  ['Despair', 'Remembering']               ['Lonely', 'Hiding']   \n",
              "\n",
              "                intern_main  \n",
              "0   ['Sand', 'Abandonment']  \n",
              "1  ['Solitude', 'Solitude']  \n",
              "2   ['Portrait', 'Friends']  \n",
              "3        ['Child', 'Child']  \n",
              "4     ['Solemn', 'Blanket']  "
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/real_all_descriptions_modified.csv\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwzVIaIQUvHK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "def cosine_similarity(embeddings1,embeddings2):\n",
        "  # embeddings1 = torch.from_numpy(embeddings1)\n",
        "  # embeddings2 = torch.from_numpy(embeddings2)\n",
        "  similarity = torch.nn.functional.cosine_similarity(\n",
        "            embeddings1,\n",
        "            embeddings2,\n",
        "            dim=0\n",
        "        )\n",
        "  return similarity.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNJJK7tYsIPS"
      },
      "outputs": [],
      "source": [
        "def consistant_main_character(internvl_word_embeddings):\n",
        "  score = []\n",
        "  for i in range(len(internvl_word_embeddings)):\n",
        "    c_score = []\n",
        "    for j in range(len(internvl_word_embeddings[i])-1):\n",
        "      c_score.append(cosine_similarity(internvl_word_embeddings[i][j],internvl_word_embeddings[i][j+1]))\n",
        "\n",
        "    score.append(1-(sum(c_score)/len(c_score)))\n",
        "\n",
        "  return sum(score)/len(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRDAM4RpgvLU",
        "outputId": "103cac6e-f320-4721-dbaf-bf8b27d1b4b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  longpoems.zip\n",
            "  inflating: content/StoryDiffusion/long_poems/18/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/18/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/18/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/18/3.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/15/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/15/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/15/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/15/3.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/6/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/6/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/6/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/10/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/10/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/10/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/19/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/19/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/19/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/19/3.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/5/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/5/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/5/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/11/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/11/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/11/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/16/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/16/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/16/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/16/3.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/4/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/4/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/4/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/4/3.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/17/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/17/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/17/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/17/3.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/14/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/14/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/14/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/2/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/2/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/2/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/2/3.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/3/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/3/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/3/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/3/3.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/1/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/1/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/1/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/1/3.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/13/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/13/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/13/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/0/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/0/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/0/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/0/3.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/8/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/8/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/8/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/9/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/9/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/9/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/7/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/7/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/7/2.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/12/1.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/12/0.png  \n",
            "  inflating: content/StoryDiffusion/long_poems/12/2.png  \n",
            "Archive:  fantasypoems.zip\n",
            "  inflating: content/StoryDiffusion/fantasy_poems/18/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/18/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/18/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/15/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/15/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/15/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/6/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/6/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/6/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/10/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/10/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/10/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/19/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/19/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/19/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/5/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/5/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/5/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/11/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/11/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/11/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/16/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/16/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/16/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/4/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/4/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/4/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/17/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/17/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/17/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/14/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/14/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/14/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/2/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/2/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/2/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/2/3.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/3/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/3/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/3/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/1/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/1/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/1/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/1/3.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/13/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/13/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/13/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/0/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/0/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/0/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/0/3.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/8/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/8/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/8/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/9/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/9/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/9/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/7/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/7/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/7/2.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/12/1.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/12/0.png  \n",
            "  inflating: content/StoryDiffusion/fantasy_poems/12/2.png  \n",
            "Archive:  realpoems.zip\n",
            "  inflating: content/StoryDiffusion/real_poems/18/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/18/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/15/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/15/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/6/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/6/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/10/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/10/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/19/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/19/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/5/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/5/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/11/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/11/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/16/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/16/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/4/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/4/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/17/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/17/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/14/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/14/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/2/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/2/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/3/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/3/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/1/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/1/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/13/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/13/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/0/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/0/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/8/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/8/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/9/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/9/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/7/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/7/0.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/12/1.png  \n",
            "  inflating: content/StoryDiffusion/real_poems/12/0.png  \n"
          ]
        }
      ],
      "source": [
        "!unzip longpoems.zip\n",
        "!unzip fantasypoems.zip\n",
        "!unzip realpoems.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNODk5lQep_W",
        "outputId": "8fd592df-f0e0-4b18-c549-6603d5ba7637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting decord\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from decord) (1.26.4)\n",
            "Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: decord\n",
            "Successfully installed decord-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install decord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "9OrYm_hkC4QW",
        "outputId": "65fae57b-8535-401e-99a9-35275a25e487"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "234212e301b94553ab190bc9d92a19bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0150be7d88594fbcb881bf8a364fadc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model_index.json:   0%|          | 0.00/680 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cf81dee7038482b95755a46a8ae737a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4bf7435c4b541e599257cf5a14147e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "scheduler%2Fscheduler_config.json:   0%|          | 0.00/561 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d54b9e1ef3e244d4911e4d8976fb083d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer%2Fmerges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e4d8926b7d74c738499062c83463639",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer%2Ftokenizer_config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4c18c69552642038427de0e3f3e5c29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "text_encoder%2Fconfig.json:   0%|          | 0.00/560 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed7f1b4dddda475eba086b742ded0ead",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.fp16.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "204f899dc4884630b422c7e8fb684c77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer%2Fspecial_tokens_map.json:   0%|          | 0.00/586 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f858daa832214441bdad277da2ae1c23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "text_encoder_2%2Fconfig.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb3825aae1e4410b9f763feb35f771cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.fp16.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52bdd61b973f412caf98b3d3249b16ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer%2Fvocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ad6c8b5fa9847c59032e124169b4819",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_2%2Ftokenizer_config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa33e1a7fee347c9bd1fa9c4546d1e75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_2%2Fspecial_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76dc1f72fadd41cc98ec4a8717520787",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "unet%2Fconfig.json:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7016a174bfe741a88ad501690a34014e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/5.14G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e867993d58645f7bf0061702f8a9c76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vae%2Fconfig.json:   0%|          | 0.00/602 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a620c11ff634f8db65c3e300bb7defa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "976fdc7a203140c987990a546680d0be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"playgroundai/playground-v2-1024px-aesthetic\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    add_watermarker=False,\n",
        "    variant=\"fp16\"\n",
        ")\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "model = \"playground\"\n",
        "os.mkdir(f\"{model}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjjI_060f2wb",
        "outputId": "2ee4c974-abb2-4ae1-e84a-9dc8340af60f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python version is above 3.10, patching the collections module.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoModelForCausalLM\n",
        "from janus.models import MultiModalityCausalLM, VLChatProcessor\n",
        "from janus.utils.io import load_pil_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "jvGjB5vJgE-e",
        "outputId": "00fc846e-3a11-42f6-ded8-08d70b0955d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edc08f9d477e4a06b273da893c874d32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/346 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f58dc61ece5c465c941c5fb5394e0ca3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5a8e392bc7242a8a770f277ed9f910d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/4.72M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6109d32dcb34ade9e75403eb226214a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/344 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "884bd81ffa264dc99e641afac0ab42d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some kwargs in processor config are unused and will not have any effect: add_special_token, sft_format, image_tag, mask_prompt, ignore_id, num_image_tokens. \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4a5f95426ae4120987e577c61a55403",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9080993413b43e7b4ff71e684dcbe90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin.index.json:   0%|          | 0.00/89.0k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b7d447d069543c1b5fd3159c5ffc51d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f71856eeddda415b82f08f7cee50e1d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.99G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9787801c26f24e16a805cfac8a3f1407",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/92.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6108954b5ed549ba816045a2a211af15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.85G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29a2c5efc7c948fbb78ed5892d2e450c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define model path\n",
        "model_path = \"deepseek-ai/Janus-Pro-7B\"\n",
        "# Load processor and tokenizer\n",
        "vl_chat_processor = VLChatProcessor.from_pretrained(model_path)\n",
        "tokenizer = vl_chat_processor.tokenizer\n",
        "# Load model with remote code enabled\n",
        "vl_gpt = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
        "# Move model to GPU\n",
        "vl_gpt = vl_gpt.to(torch.bfloat16).cuda().eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFAin-IQhNe6"
      },
      "outputs": [],
      "source": [
        "conversation = [\n",
        "    {\n",
        "        \"role\": \"<|User|>\",\n",
        "        \"content\": \"1024 x 1024 pixels batman flying with a cape\"\n",
        "    },\n",
        "    {\"role\": \"<|Assistant|>\", \"content\": \"\"}\n",
        "]\n",
        "\n",
        "sft_format = vl_chat_processor.apply_sft_template_for_multi_turn_prompts(\n",
        "    conversations=conversation,\n",
        "    sft_format=vl_chat_processor.sft_format,\n",
        "    system_prompt=\"\",\n",
        ")\n",
        "prompt = sft_format + vl_chat_processor.image_start_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_F4fEChhmqp"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def generate(\n",
        "    mmgpt: MultiModalityCausalLM,\n",
        "    vl_chat_processor: VLChatProcessor,\n",
        "    prompt: str,\n",
        "    temperature: float = 1,\n",
        "    parallel_size: int = 1,\n",
        "    cfg_weight: float = 5,\n",
        "    image_token_num_per_image: int = 576,\n",
        "    img_size: int = 384,\n",
        "    patch_size: int = 16,\n",
        "):\n",
        "    input_ids = vl_chat_processor.tokenizer.encode(prompt)\n",
        "    input_ids = torch.LongTensor(input_ids)\n",
        "\n",
        "    tokens = torch.zeros((parallel_size*2, len(input_ids)), dtype=torch.int).cuda()\n",
        "\n",
        "    for i in range(parallel_size*2):\n",
        "        tokens[i, :] = input_ids\n",
        "        if i % 2 != 0:\n",
        "            tokens[i, 1:-1] = vl_chat_processor.pad_id\n",
        "\n",
        "    inputs_embeds = mmgpt.language_model.get_input_embeddings()(tokens)\n",
        "\n",
        "    generated_tokens = torch.zeros((parallel_size, image_token_num_per_image), dtype=torch.int).cuda()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(image_token_num_per_image):\n",
        "        outputs = mmgpt.language_model.model(inputs_embeds=inputs_embeds, use_cache=True, past_key_values=outputs.past_key_values if i != 0 else None)\n",
        "        hidden_states = outputs.last_hidden_state\n",
        "\n",
        "        logits = mmgpt.gen_head(hidden_states[:, -1, :])\n",
        "        logit_cond = logits[0::2, :]\n",
        "        logit_uncond = logits[1::2, :]\n",
        "\n",
        "        logits = logit_uncond + cfg_weight * (logit_cond-logit_uncond)\n",
        "        probs = torch.softmax(logits / temperature, dim=-1)\n",
        "\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "        generated_tokens[:, i] = next_token.squeeze(dim=-1)\n",
        "\n",
        "        next_token = torch.cat([next_token.unsqueeze(dim=1), next_token.unsqueeze(dim=1)], dim=1).view(-1)\n",
        "        img_embeds = mmgpt.prepare_gen_img_embeds(next_token)\n",
        "        inputs_embeds = img_embeds.unsqueeze(dim=1)\n",
        "\n",
        "\n",
        "    dec = mmgpt.gen_vision_model.decode_code(generated_tokens.to(dtype=torch.int), shape=[parallel_size, 8, img_size//patch_size, img_size//patch_size])\n",
        "    dec = dec.to(torch.float32).cpu().numpy().transpose(0, 2, 3, 1)\n",
        "\n",
        "    dec = np.clip((dec + 1) / 2 * 255, 0, 255)\n",
        "\n",
        "    visual_img = np.zeros((parallel_size, img_size, img_size, 3), dtype=np.uint8)\n",
        "    visual_img[:, :, :] = dec\n",
        "\n",
        "    os.makedirs('generated_samples', exist_ok=True)\n",
        "    return visual_img[0]\n",
        "    # for i in range(parallel_size):\n",
        "    #     save_path = os.path.join('generated_samples', \"img_{}.jpg\".format(i))\n",
        "    #     PIL.Image.fromarray(visual_img[i]).save(save_path)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "image=generate(\n",
        "    vl_gpt,\n",
        "    vl_chat_processor,\n",
        "    prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwC0Y3xfi1wp"
      },
      "outputs": [],
      "source": [
        "PIL.Image.fromarray(image).save(\"as.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TO7zMqs6v9Bo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# model = \"deepseek\"\n",
        "# os.mkdir(f\"{model}\")\n",
        "folder = \"long\"\n",
        "os.mkdir(f\"{model}/{folder}\")\n",
        "df = pd.read_csv(f\"/content/{folder}_all_descriptions_modified.csv\")\n",
        "\n",
        "for i in range(len(df)):\n",
        "  os.mkdir(f\"{model}/{folder}/{i}\")\n",
        "  for j in range(len(eval(df[\"updated_descriptions\"][i]))):\n",
        "    prompt = eval(df[\"updated_descriptions\"][i])[j]\n",
        "    conversation = [\n",
        "        {\n",
        "            \"role\": \"<|User|>\",\n",
        "            \"content\": f\"{prompt}\"\n",
        "        },\n",
        "        {\"role\": \"<|Assistant|>\", \"content\": \"\"}\n",
        "    ]\n",
        "\n",
        "    sft_format = vl_chat_processor.apply_sft_template_for_multi_turn_prompts(\n",
        "        conversations=conversation,\n",
        "        sft_format=vl_chat_processor.sft_format,\n",
        "        system_prompt=\"\",\n",
        "    )\n",
        "    prompt = sft_format + vl_chat_processor.image_start_tag\n",
        "    image=generate(\n",
        "        vl_gpt,\n",
        "        vl_chat_processor,\n",
        "        prompt,\n",
        "    )\n",
        "    PIL.Image.fromarray(image).save(f\"{model}/{folder}/{i}/{j}.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5E_3tOQfHOQ"
      },
      "outputs": [],
      "source": [
        "image.images[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
